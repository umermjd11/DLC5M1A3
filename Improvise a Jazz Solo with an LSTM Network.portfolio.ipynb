{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 15px; \n",
    "            color: #FFC07F; \n",
    "            margin: 15px; \n",
    "            font-size: 1.5em; \n",
    "            display: fill; \n",
    "            border-radius: 10px; \n",
    "            border: 2px solid #FF9F00; \n",
    "            background-color: #2F2E41; \n",
    "            overflow: hidden; \n",
    "            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);\">\n",
    "    <center>\n",
    "        <a id=\"title\"></a>\n",
    "        <b style=\"font-size: 1.8em; color: #FFC07F;\">Generating Jazz Solos with LSTM Networks</b><br><br>\n",
    "        <a id=\"top\"></a>\n",
    "        <b style=\"font-size: 1.4em; color: #FFC07F;\">Table of Contents</b>\n",
    "    </center>\n",
    "    <br>\n",
    "    <ul style=\"list-style-type: none; padding-left: 0;\">\n",
    "        <ul style=\"list-style-type: none; padding-left: 0;\">\n",
    "            <li style=\"padding: 8px 0;\">\n",
    "                <a href=\"#1\" style=\"color: #FFCC66; text-decoration: none;\">1 - Overview</a>\n",
    "            </li>\n",
    "            <ul style=\"list-style-type: none; padding-left: 20px;\">\n",
    "                <li style=\"padding: 8px 0;\">\n",
    "                    <a href=\"#1-1\" style=\"color: #FFCC66; text-decoration: none; font-weight: normal; font-size: 16px;\">1.1. Generating Jazz Solos with LSTM Networks</a>\n",
    "                </li>\n",
    "                <ul style=\"list-style-type: none; padding-left: 10;\">\n",
    "                    <li style=\"padding: 8px 0;\">\n",
    "                    <a href=\"#1-1-1\" style=\"color: #FFCC66; text-decoration: none; font-weight: normal; font-size: 14px;\">1.1.1. Objectives</a>\n",
    "                    </li>\n",
    "                    <li style=\"padding: 8px 0;\">\n",
    "                    <a href=\"#1-1-1\" style=\"color: #FFCC66; text-decoration: none; font-weight: normal; font-size: 14px;\">1.1.2. Problem Statement</a>\n",
    "                    </li>\n",
    "                </ul>\n",
    "            </ul>\n",
    "        </ul>\n",
    "        <li style=\"padding: 8px 0;\">\n",
    "            <a href=\"#2\" style=\"color: #FFCC66; text-decoration: none;\">2 - Imports</a>\n",
    "        </li>\n",
    "        <ul style=\"list-style-type: none; padding-left: 0;\">\n",
    "            <li style=\"padding: 8px 0;\">\n",
    "                <a href=\"#3\" style=\"color: #FFCC66; text-decoration: none;\">3 - Data Preparation</a>\n",
    "            </li>\n",
    "            <ul style=\"list-style-type: none; padding-left: 20px;\">\n",
    "                <li style=\"padding: 8px 0;\">\n",
    "                    <a href=\"#3-1\" style=\"color: #FFCC66; text-decoration: none; font-weight: normal; font-size: 16px;\">3.1. Dataset</a>\n",
    "                </li>\n",
    "                <li style=\"padding: 8px 0;\">\n",
    "                    <a href=\"#3-2\" style=\"color: #FFCC66; text-decoration: none; font-weight: normal; font-size: 16px;\">3.2. Dataset Overview</a>\n",
    "                </li>  \n",
    "            </ul>\n",
    "        </ul>\n",
    "        <ul style=\"list-style-type: none; padding-left: 0;\">\n",
    "            <li style=\"padding: 8px 0;\">\n",
    "                <a href=\"#4\" style=\"color: #FFCC66; text-decoration: none;\">4 - Building the model</a>\n",
    "            </li>\n",
    "            <ul style=\"list-style-type: none; padding-left: 20px;\">\n",
    "                <li style=\"padding: 8px 0;\">\n",
    "                    <a href=\"#4-1\" style=\"color: #FFCC66; text-decoration: none; font-weight: normal; font-size: 16px;\">4.1 - Model Overview</a>\n",
    "                </li>\n",
    "                <li style=\"padding: 8px 0;\">\n",
    "                    <a href=\"#4-2\" style=\"color: #FFCC66; text-decoration: none; font-weight: normal; font-size: 16px;\">4.2 - Building the model</a>\n",
    "                </li>  \n",
    "            </ul>\n",
    "        </ul>\n",
    "        <li style=\"padding: 8px 0;\">\n",
    "            <a href=\"#5\" style=\"color: #FFCC66; text-decoration: none;\">5 - Training the model</a>\n",
    "        </li>\n",
    "        <ul style=\"list-style-type: none; padding-left: 0;\">\n",
    "            <li style=\"padding: 8px 0;\">\n",
    "                <a href=\"#6\" style=\"color: #FFCC66; text-decoration: none;\">6 - Model Inference - Generating music</a>\n",
    "            </li>\n",
    "            <ul style=\"list-style-type: none; padding-left: 20px;\">\n",
    "                <li style=\"padding: 8px 0;\">\n",
    "                    <a href=\"#6-1\" style=\"color: #FFCC66; text-decoration: none; font-weight: normal; font-size: 16px;\">6.1 - Predicting & Sampling</a>\n",
    "                </li>\n",
    "                <li style=\"padding: 8px 0;\">\n",
    "                    <a href=\"#4-2\" style=\"color: #FFCC66; text-decoration: none; font-weight: normal; font-size: 16px;\">6.2 - Generating Music</a>\n",
    "                </li>  \n",
    "            </ul>\n",
    "        </ul>\n",
    "        <li style=\"padding: 8px 0;\">\n",
    "            <a href=\"#7\" style=\"color: #FFCC66; text-decoration: none;\">7 - Congratulations!</a>\n",
    "        </li>\n",
    "        <li style=\"padding: 8px 0;\">\n",
    "            <a href=\"#8\" style=\"color: #FFCC66; text-decoration: none;\">8 - References</a>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "<h1 style=\"background: #FFC07F; border: 0; color: #2F2E41; \n",
    "    box-shadow: 4px 4px 8px rgba(0, 0, 0, 0.3); \n",
    "    padding: 10px; border-radius: 10px; margin: 15px 0;\">\n",
    "    <center style=\"color: #2F2E41;\">1 - Overview</center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1-1\"></a>\n",
    "\n",
    "## 1.1. Generating Jazz Solos with LSTM Networks\n",
    "\n",
    "In this notebook, we implement a Long Short-Term Memory (LSTM) network to generate music. Specifically, the model is trained to produce jazz solos, leveraging deep learning techniques to simulate the improvisational nature of jazz performance.\n",
    "\n",
    "<a id=\"1-1-1\"></a>\n",
    "\n",
    "### 1.1.1. Objectives\n",
    "- Apply LSTM architecture to the task of music generation.\n",
    "- Explore the use of deep learning to generate jazz compositions.\n",
    "\n",
    "<a id=\"1-1-2\"></a>\n",
    "### 1.1.2. Problem Statement\n",
    "\n",
    "This project aims to generate jazz music compositions using deep learning techniques. Specifically, we employ an LSTM network to produce novel jazz solos, derived from a dataset of performed works. This approach enables the creation of music without requiring traditional knowledge of musical instruments or composition.\n",
    "\n",
    "<img src=\"images/jazz.jpg\" style=\"width:450;height:300px;\">\n",
    "\n",
    "Through training, the LSTM network learns to generate jazz solos that are stylistically consistent with the original dataset, allowing us to synthesize pieces that capture the improvisational essence of jazz.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "<h1 style=\"background: #FFC07F; border: 0; color: #2F2E41; \n",
    "    box-shadow: 4px 4px 8px rgba(0, 0, 0, 0.3); \n",
    "    padding: 10px; border-radius: 10px; margin: 15px 0;\">\n",
    "    <center style=\"color: #2F2E41;\">2 - Imports</center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # Suppresses INFO and WARNING logs\n",
    "from __future__ import print_function\n",
    "import IPython\n",
    "import sys\n",
    "import numpy as np\n",
    "from keras.models import load_model, Model\n",
    "from keras.layers import Dense, Activation, Dropout, Input, LSTM, Reshape, Lambda, RepeatVector\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from music21 import *\n",
    "\n",
    "from grammar import *\n",
    "from qa import *\n",
    "from preprocess import * \n",
    "from music_utils import *\n",
    "from data_utils import *\n",
    "\n",
    "from midi2audio import FluidSynth\n",
    "from pydub import AudioSegment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "<h1 style=\"background: #FFC07F; border: 0; color: #2F2E41; \n",
    "    box-shadow: 4px 4px 8px rgba(0, 0, 0, 0.3); \n",
    "    padding: 10px; border-radius: 10px; margin: 15px 0;\">\n",
    "    <center style=\"color: #2F2E41;\">3 - Data Preparation</center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3-1\"></a>\n",
    "\n",
    "### 3.1. Dataset\n",
    "\n",
    "In this project, we will train the algorithm using a corpus of jazz music. The dataset consists of musical sequences that capture the stylistic elements of jazz solos. By training on this corpus, the model learns patterns and structures characteristic of jazz improvisation.\n",
    "\n",
    "Below is a snippet of [audio](https://raw.githubusercontent.com/umermjd11/DLC5M1A3/master/data/30s_seq.mp3) from the training set:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<audio controls>\n",
    "    <source src=\"https://raw.githubusercontent.com/umermjd11/DLC5M1A3/master/data/30s_seq.mp3\" type=\"audio/mp3\">\n",
    "    Your browser does not support the audio element.\n",
    "</audio>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have preprocessed the musical data into discrete musical \"values.\" Each value can be informally understood as a note, represented by both a pitch and a duration. For instance, pressing a piano key for 0.5 seconds produces a note. \n",
    "\n",
    "In music theory, a \"value\" encompasses more complexity, including the ability to represent multiple notes played simultaneously (e.g., chords, where two or more keys are pressed together). However, these nuances of music theory are beyond the scope of this project. For our purposes, it is sufficient to understand that the dataset consists of sequences of these musical values, which our Recurrent Neural Network (RNN) model will learn to generate.\n",
    "\n",
    "Our music generation system utilizes a total of 90 unique values. The following code loads the raw music data and preprocesses it into this format. Note that this step may take a few minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X: (60, 30, 90)\n",
      "number of training examples: 60\n",
      "Tx (length of sequence): 30\n",
      "total # of unique values: 90\n",
      "Shape of Y: (30, 60, 90)\n"
     ]
    }
   ],
   "source": [
    "X, Y, n_values, indices_values = load_music_utils()\n",
    "print('shape of X:', X.shape)\n",
    "print('number of training examples:', X.shape[0])\n",
    "print('Tx (length of sequence):', X.shape[1])\n",
    "print('total # of unique values:', n_values)\n",
    "print('Shape of Y:', Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3-2\"></a>\n",
    "\n",
    "### 3.2. Dataset Overview\n",
    "\n",
    "#### Input Data: `X`\n",
    "\n",
    "We have loaded the input data, denoted by `X`, which is structured as a 3-dimensional array with shape $(m, T_x, 90)$. Here, the dimensions represent:\n",
    "\n",
    "- $m$: The number of training examples.\n",
    "- $T_x$: The number of time steps per training example. In this case, $T_x = 30$, indicating that each example consists of 30 sequential musical values.\n",
    "- 90: The number of possible musical values at each time step, encoded as one-hot vectors.\n",
    "\n",
    "Each entry of the array, $X[i, t, :]$, corresponds to the one-hot encoded representation of the musical value observed in the $i$-th training example at time step $t$. Specifically, $X[i, t, :]$ is a vector with 90 components, where one element is set to 1, and the rest are 0, indicating the specific musical value at that time step.\n",
    "\n",
    "#### Target Data: `Y`\n",
    "\n",
    "The target data, `Y`, is structured similarly to `X` but shifted by one time step to represent the past values. This shift aligns with the goal of training a sequential model to predict the next musical value based on the preceding values.\n",
    "\n",
    "While the input data `X` is structured with dimensions $(m, T_x, 90)$, the target data `Y` is reshaped for convenience to $(T_y, m, 90)$, where $T_y = T_x$. This reordering of dimensions is particularly useful when feeding the data into an LSTM or other recurrent neural networks, which expect sequences of inputs at each time step.\n",
    "\n",
    "The sequence model will be trained to predict $y^{\\langle t \\rangle}$ given the preceding inputs $x^{\\langle 1 \\rangle}, x^{\\langle 2 \\rangle}, \\ldots, x^{\\langle t \\rangle}$. This formulation allows the network to learn temporal dependencies in the data, enabling it to anticipate the next musical value based on prior context.\n",
    "\n",
    "#### Additional Information\n",
    "\n",
    "- `n_values`: This variable specifies the number of unique musical values in the dataset, which is 90.\n",
    "- `indices_values`: A Python dictionary mapping integer indices (from 0 to 89) to the corresponding musical values. This dictionary facilitates the conversion between the one-hot encoded vectors and the actual musical values they represent.\n",
    "\n",
    "#### Summary\n",
    "\n",
    "In summary, we have a dataset of musical sequences where each example consists of 30 time steps. The input data `X` is a 3D array containing one-hot encoded musical values, and the target data `Y` is a version of `X` shifted by one time step, formatted for convenience in sequential modeling. The model will learn to predict future musical values based on past sequences, using a total of 90 possible musical values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "<h1 style=\"background: #FFC07F; border: 0; color: #2F2E41; \n",
    "    box-shadow: 4px 4px 8px rgba(0, 0, 0, 0.3); \n",
    "    padding: 10px; border-radius: 10px; margin: 15px 0;\">\n",
    "    <center style=\"color: #2F2E41;\">4 - Building the model</center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4-1\"></a>\n",
    "\n",
    "### 4.1 - Model Overview\n",
    "\n",
    "The architecture of the model used in this study is an LSTM-based network, adapted for the task of music generation. We will construct the model using the Keras deep learning library. \n",
    "\n",
    "The architecture is illustrated below:\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"images/music_generation.png\" style=\"width:600px;height:400px;\">\n",
    "  <br>\n",
    "  <caption>\n",
    "    <font color=\"#00796b\" style=\"font-size: 1.2em; font-weight: bold;\">\n",
    "      <b>Figure 1</b>: LSTM model architecture for music generation\n",
    "    </font>\n",
    "  </caption>\n",
    "</div>\n",
    "\n",
    "The input to the model is represented as $X = (x^{\\langle 1 \\rangle}, x^{\\langle 2 \\rangle}, \\dots, x^{\\langle T_x \\rangle})$, where $T_x$ denotes the window size scanned over the musical corpus. Each $x^{\\langle t \\rangle}$ corresponds to an index representing a musical value (e.g., \"A, 0.250, <m2, P-4>\"). The model learns to predict the next value, $\\hat{y}$, in the sequence.\n",
    "\n",
    "The model is trained on random snippets of 30 consecutive values extracted from a longer music piece. Unlike previous models, we do not need to explicitly define the first input as $x^{\\langle 1 \\rangle} = \\vec{0}$ to indicate the start of a sequence. In this case, the snippets are randomly selected, and each snippet is likely to start in the middle of a musical piece. For ease of vectorization, all snippets are standardized to a length of $T_x = 30$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4-2\"></a>\n",
    "\n",
    "### 4.2 - Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this section, we will build a model designed to learn musical patterns from sequential data. The model will take as input sequences $X$ with shape $(m, T_x, 90)$, where:\n",
    "- $m$ is the number of examples in the dataset,\n",
    "- $T_x$ is the length of each input sequence, and\n",
    "- 90 represents the number of features per time step, corresponding to different musical notes.\n",
    "\n",
    "The model will produce output sequences $Y$ with shape $(T_y, m, 90)$, where $T_y$ corresponds to the desired output sequence length, which may differ from $T_x$.\n",
    "\n",
    "To achieve this, we will use a Long Short-Term Memory (LSTM) network with 64-dimensional hidden states. Specifically, we set `n_a = 64` to define the dimensionality of the LSTM's hidden state.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_a = 64 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequence Generation with Recurrent Neural Networks\n",
    "\n",
    "For sequence generation tasks such as music composition, the challenge arises from the fact that the entire input sequence is not available during testing. Unlike classification tasks, where the model is provided with the complete sequence upfront, in sequence generation, the model generates one element at a time. At each time step $t$, the model must generate the next input $x^{\\langle t \\rangle}$ based on the previous output $y^{\\langle t-1 \\rangle}$. Therefore, the model must be designed to handle this autoregressive process.\n",
    "\n",
    "In Keras, this can be accomplished by implementing a custom for-loop to iterate through the time steps, calling the LSTM layer at each time step. It is crucial that the weights of the LSTM are shared across all time steps to ensure consistency in learning. This is achieved by defining the LSTM layer as a global object and reusing it throughout the sequence generation process.\n",
    "\n",
    "#### Keras Layer Objects\n",
    "\n",
    "To implement this model, we define several Keras layer objects as global variables. These include:\n",
    "- `reshapor`: A layer that reshapes the input.\n",
    "- `LSTM_cell`: The LSTM layer used for sequence generation.\n",
    "- `densor`: A dense layer with a softmax activation function to predict the output.\n",
    "\n",
    "Each of these layer objects can be used within the `djmodel()` function to propagate the input through the model at each time step. For example, calling `reshapor(X)` will pass the input $X$ through the reshaping operation, and `LSTM_cell(X)` will execute one step of the LSTM.\n",
    "\n",
    "#### Implementing the `djmodel()` Function\n",
    "\n",
    "The `djmodel()` function is responsible for executing the sequence generation process. The key steps for implementing this function are as follows:\n",
    "\n",
    "1. **Create an Empty List for Outputs**  \n",
    "   Initialize an empty list named `outputs` to store the outputs of the LSTM at each time step.\n",
    "\n",
    "2. **Iterate Over Time Steps**  \n",
    "   Use a for-loop to iterate through the time steps $t = 1, \\ldots, T_x$. For each time step, perform the following operations:\n",
    "\n",
    "   A. **Select the Time-Step Vector**  \n",
    "      Extract the $t$-th time-step vector from $X$. The shape of this selection will be $(90,)$. This can be achieved by creating a custom `Lambda` layer in Keras:\n",
    "      \n",
    "      ```python\n",
    "      x = Lambda(lambda x: X[:,t,:])(X)\n",
    "      ```\n",
    "\n",
    "      The `Lambda` function defines a temporary operation to extract the relevant time-step vector, and this function is converted into a Keras layer to be applied to $X$.\n",
    "\n",
    "   B. **Reshape the Input Vector**  \n",
    "      Reshape the vector $x$ to have a shape of $(1, 90)$. We may find the `reshapor()` layer helpful for this transformation.\n",
    "\n",
    "   C. **Run Through the LSTM Cell**  \n",
    "      Pass the reshaped vector $x$ through one step of the LSTM. The LSTM should be initialized with the hidden state $a$ and cell state $c$ from the previous time step:\n",
    "      \n",
    "      ```python\n",
    "      a, _, c = LSTM_cell(input_x, initial_state=[previous_hidden_state, previous_cell_state])\n",
    "      ```\n",
    "\n",
    "      This ensures that the LSTM's hidden and cell states are updated at each time step.\n",
    "\n",
    "   D. **Dense Layer Activation**  \n",
    "      After passing through the LSTM, the output should be propagated through a dense layer with a softmax activation function using the `densor` layer:\n",
    "      \n",
    "      ```python\n",
    "      prediction = densor(a)\n",
    "      ```\n",
    "\n",
    "      This will generate the predicted output for the current time step.\n",
    "\n",
    "   E. **Store the Output**  \n",
    "      Append the predicted value to the `outputs` list to collect the predictions at each time step.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshapor = Reshape((1, 90))                        # Used in Step 2.B of djmodel(), below\n",
    "LSTM_cell = LSTM(n_a, return_state = True)         # Used in Step 2.C\n",
    "densor = Dense(n_values, activation='softmax')     # Used in Step 2.D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def djmodel(Tx, n_a, n_values):\n",
    "    \"\"\"\n",
    "    Implements a sequence generation model for musical pattern learning using LSTM.\n",
    "    \n",
    "    Arguments:\n",
    "    Tx -- Length of the input sequence in the corpus.\n",
    "    n_a -- Number of activations (dimensionality of the hidden state in the LSTM).\n",
    "    n_values -- Number of unique values (features) in the music data (e.g., musical notes).\n",
    "    \n",
    "    Returns:\n",
    "    model -- A Keras Model object representing the sequence generation model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1a: Define the input of the model with shape (Tx, n_values)\n",
    "    X = Input(shape=(Tx, n_values), name=\"X\")\n",
    "    \n",
    "    # Step 1b: Define initial hidden state (a0) and cell state (c0) for the LSTM decoder\n",
    "    a0 = Input(shape=(n_a,), name='a0')\n",
    "    c0 = Input(shape=(n_a,), name='c0')\n",
    "    \n",
    "    # Set the initial states to be used in the LSTM layer\n",
    "    a = a0\n",
    "    c = c0\n",
    "    \n",
    "    # Step 1c: Create an empty list to store outputs for each time step\n",
    "    outputs = []\n",
    "    \n",
    "    # Step 2: Iterate over the sequence steps (Tx)\n",
    "    for t in range(Tx):\n",
    "        \n",
    "        # Step 2.A: Select the t-th time step vector from X\n",
    "        x_t = Lambda(lambda x: x[:, t, :])(X)  # Extract the t-th time step\n",
    "        \n",
    "        # Step 2.B: Reshape x_t to shape (1, n_values) using reshapor\n",
    "        x_t_reshaped = reshapor(x_t)  # Reshapes to (1, n_values)\n",
    "        \n",
    "        # Step 4.C: Pass the reshaped input through one step of the LSTM cell\n",
    "        a, _, c = LSTM_cell(x_t_reshaped, initial_state=[a, c])  # LSTM update with previous state\n",
    "        \n",
    "        # Step 4.D: Apply the dense layer to the output of the LSTM cell\n",
    "        out_t = densor(a)  # Apply dense layer with softmax activation\n",
    "        \n",
    "        # Step 4.E: Append the output of the current time step to the outputs list\n",
    "        outputs.append(out_t)\n",
    "    \n",
    "    # Step 5: Create the Keras model instance using the defined inputs and outputs\n",
    "    model = Model(inputs=[X, a0, c0], outputs=outputs)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will define and compile the model. For this implementation, we set the sequence length to $T_x = 30$, the dimensionality of the LSTM activations to $n_a = 64$, and the number of unique values in the music data to $n_{\\text{values}} = 90$. The model is then compiled using the Adam optimizer and categorical cross-entropy loss function, preparing it for training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = djmodel(Tx = 30 , n_a = 64, n_values = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "<h1 style=\"background: #FFC07F; border: 0; color: #2F2E41; \n",
    "    box-shadow: 4px 4px 8px rgba(0, 0, 0, 0.3); \n",
    "    padding: 10px; border-radius: 10px; margin: 15px 0;\">\n",
    "    <center style=\"color: #2F2E41;\">5 - Training the model</center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets initialize `a0` and `c0` for the LSTM's initial state to be zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 60\n",
    "a0 = np.zeros((m, n_a))\n",
    "c0 = np.zeros((m, n_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now proceed with fitting the model. To do so, we first convert $Y$ into a list format, as the cost function requires $Y$ to be provided in this structure, with one list item per time step. Specifically, `list(Y)` results in a list containing 30 items, each with the shape $(60, 90)$. The model will be trained for 100 epochs, which may take a few minutes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - dense_1_accuracy: 0.7056 - dense_1_accuracy_1: 0.6937 - dense_1_accuracy_10: 0.6292 - dense_1_accuracy_11: 0.6833 - dense_1_accuracy_12: 0.5437 - dense_1_accuracy_13: 0.5965 - dense_1_accuracy_14: 0.5653 - dense_1_accuracy_15: 0.5542 - dense_1_accuracy_16: 0.4889 - dense_1_accuracy_17: 0.6194 - dense_1_accuracy_18: 0.4993 - dense_1_accuracy_19: 0.5097 - dense_1_accuracy_2: 0.6833 - dense_1_accuracy_20: 0.5104 - dense_1_accuracy_21: 0.4778 - dense_1_accuracy_22: 0.5090 - dense_1_accuracy_23: 0.3910 - dense_1_accuracy_24: 0.5528 - dense_1_accuracy_25: 0.4556 - dense_1_accuracy_26: 0.3382 - dense_1_accuracy_27: 0.2292 - dense_1_accuracy_28: 0.5104 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6937 - dense_1_accuracy_4: 0.6833 - dense_1_accuracy_5: 0.6729 - dense_1_accuracy_6: 0.6840 - dense_1_accuracy_7: 0.6514 - dense_1_accuracy_8: 0.6514 - dense_1_accuracy_9: 0.6403 - dense_1_loss: 0.0000e+00 - loss: 37.4718\n",
      "Epoch 2/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - dense_1_accuracy: 0.6535 - dense_1_accuracy_1: 0.6312 - dense_1_accuracy_10: 0.5771 - dense_1_accuracy_11: 0.6208 - dense_1_accuracy_12: 0.5542 - dense_1_accuracy_13: 0.5556 - dense_1_accuracy_14: 0.5757 - dense_1_accuracy_15: 0.5542 - dense_1_accuracy_16: 0.4354 - dense_1_accuracy_17: 0.5986 - dense_1_accuracy_18: 0.5542 - dense_1_accuracy_19: 0.4688 - dense_1_accuracy_2: 0.6312 - dense_1_accuracy_20: 0.4688 - dense_1_accuracy_21: 0.3812 - dense_1_accuracy_22: 0.4562 - dense_1_accuracy_23: 0.4139 - dense_1_accuracy_24: 0.4243 - dense_1_accuracy_25: 0.4236 - dense_1_accuracy_26: 0.3806 - dense_1_accuracy_27: 0.2062 - dense_1_accuracy_28: 0.5229 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6312 - dense_1_accuracy_4: 0.6306 - dense_1_accuracy_5: 0.6312 - dense_1_accuracy_6: 0.6424 - dense_1_accuracy_7: 0.6521 - dense_1_accuracy_8: 0.6312 - dense_1_accuracy_9: 0.5986 - dense_1_loss: 0.0000e+00 - loss: 38.5974\n",
      "Epoch 3/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - dense_1_accuracy: 0.7056 - dense_1_accuracy_1: 0.6840 - dense_1_accuracy_10: 0.6410 - dense_1_accuracy_11: 0.6625 - dense_1_accuracy_12: 0.5431 - dense_1_accuracy_13: 0.5757 - dense_1_accuracy_14: 0.5764 - dense_1_accuracy_15: 0.6076 - dense_1_accuracy_16: 0.5104 - dense_1_accuracy_17: 0.5972 - dense_1_accuracy_18: 0.5437 - dense_1_accuracy_19: 0.4889 - dense_1_accuracy_2: 0.6951 - dense_1_accuracy_20: 0.5868 - dense_1_accuracy_21: 0.4667 - dense_1_accuracy_22: 0.4903 - dense_1_accuracy_23: 0.4667 - dense_1_accuracy_24: 0.4569 - dense_1_accuracy_25: 0.4347 - dense_1_accuracy_26: 0.4444 - dense_1_accuracy_27: 0.3368 - dense_1_accuracy_28: 0.5868 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6410 - dense_1_accuracy_4: 0.6625 - dense_1_accuracy_5: 0.6625 - dense_1_accuracy_6: 0.6632 - dense_1_accuracy_7: 0.6625 - dense_1_accuracy_8: 0.6736 - dense_1_accuracy_9: 0.6299 - dense_1_loss: 0.0000e+00 - loss: 37.6139\n",
      "Epoch 4/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - dense_1_accuracy: 0.7160 - dense_1_accuracy_1: 0.6729 - dense_1_accuracy_10: 0.6201 - dense_1_accuracy_11: 0.6944 - dense_1_accuracy_12: 0.5431 - dense_1_accuracy_13: 0.5854 - dense_1_accuracy_14: 0.5847 - dense_1_accuracy_15: 0.6299 - dense_1_accuracy_16: 0.5201 - dense_1_accuracy_17: 0.5542 - dense_1_accuracy_18: 0.5639 - dense_1_accuracy_19: 0.5639 - dense_1_accuracy_2: 0.6299 - dense_1_accuracy_20: 0.5639 - dense_1_accuracy_21: 0.4882 - dense_1_accuracy_22: 0.5208 - dense_1_accuracy_23: 0.4882 - dense_1_accuracy_24: 0.5972 - dense_1_accuracy_25: 0.3375 - dense_1_accuracy_26: 0.5097 - dense_1_accuracy_27: 0.2938 - dense_1_accuracy_28: 0.5979 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6521 - dense_1_accuracy_4: 0.6625 - dense_1_accuracy_5: 0.6625 - dense_1_accuracy_6: 0.6528 - dense_1_accuracy_7: 0.6417 - dense_1_accuracy_8: 0.6208 - dense_1_accuracy_9: 0.6625 - dense_1_loss: 0.0000e+00 - loss: 37.2042\n",
      "Epoch 5/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - dense_1_accuracy: 0.6639 - dense_1_accuracy_1: 0.6312 - dense_1_accuracy_10: 0.6097 - dense_1_accuracy_11: 0.6632 - dense_1_accuracy_12: 0.5333 - dense_1_accuracy_13: 0.4889 - dense_1_accuracy_14: 0.5868 - dense_1_accuracy_15: 0.6090 - dense_1_accuracy_16: 0.4681 - dense_1_accuracy_17: 0.5556 - dense_1_accuracy_18: 0.4889 - dense_1_accuracy_19: 0.5319 - dense_1_accuracy_2: 0.5986 - dense_1_accuracy_20: 0.4896 - dense_1_accuracy_21: 0.4458 - dense_1_accuracy_22: 0.5222 - dense_1_accuracy_23: 0.4028 - dense_1_accuracy_24: 0.5007 - dense_1_accuracy_25: 0.4354 - dense_1_accuracy_26: 0.3917 - dense_1_accuracy_27: 0.2069 - dense_1_accuracy_28: 0.7368 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6208 - dense_1_accuracy_4: 0.5882 - dense_1_accuracy_5: 0.6312 - dense_1_accuracy_6: 0.6417 - dense_1_accuracy_7: 0.6312 - dense_1_accuracy_8: 0.6208 - dense_1_accuracy_9: 0.6201 - dense_1_loss: 0.0000e+00 - loss: 38.2697\n",
      "Epoch 6/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - dense_1_accuracy: 0.6639 - dense_1_accuracy_1: 0.6312 - dense_1_accuracy_10: 0.5882 - dense_1_accuracy_11: 0.6306 - dense_1_accuracy_12: 0.5118 - dense_1_accuracy_13: 0.4896 - dense_1_accuracy_14: 0.5444 - dense_1_accuracy_15: 0.5653 - dense_1_accuracy_16: 0.4250 - dense_1_accuracy_17: 0.5993 - dense_1_accuracy_18: 0.5222 - dense_1_accuracy_19: 0.4674 - dense_1_accuracy_2: 0.6312 - dense_1_accuracy_20: 0.5868 - dense_1_accuracy_21: 0.5007 - dense_1_accuracy_22: 0.5111 - dense_1_accuracy_23: 0.3181 - dense_1_accuracy_24: 0.4569 - dense_1_accuracy_25: 0.4035 - dense_1_accuracy_26: 0.4132 - dense_1_accuracy_27: 0.2410 - dense_1_accuracy_28: 0.5653 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6312 - dense_1_accuracy_4: 0.6312 - dense_1_accuracy_5: 0.6208 - dense_1_accuracy_6: 0.6424 - dense_1_accuracy_7: 0.6312 - dense_1_accuracy_8: 0.6424 - dense_1_accuracy_9: 0.6312 - dense_1_loss: 0.0000e+00 - loss: 39.2813\n",
      "Epoch 7/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - dense_1_accuracy: 0.6639 - dense_1_accuracy_1: 0.6306 - dense_1_accuracy_10: 0.6403 - dense_1_accuracy_11: 0.6417 - dense_1_accuracy_12: 0.5437 - dense_1_accuracy_13: 0.5118 - dense_1_accuracy_14: 0.5646 - dense_1_accuracy_15: 0.5431 - dense_1_accuracy_16: 0.4028 - dense_1_accuracy_17: 0.5979 - dense_1_accuracy_18: 0.5097 - dense_1_accuracy_19: 0.4236 - dense_1_accuracy_2: 0.6625 - dense_1_accuracy_20: 0.5111 - dense_1_accuracy_21: 0.5104 - dense_1_accuracy_22: 0.4778 - dense_1_accuracy_23: 0.3701 - dense_1_accuracy_24: 0.5000 - dense_1_accuracy_25: 0.4361 - dense_1_accuracy_26: 0.3910 - dense_1_accuracy_27: 0.2611 - dense_1_accuracy_28: 0.5757 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6625 - dense_1_accuracy_4: 0.6625 - dense_1_accuracy_5: 0.6410 - dense_1_accuracy_6: 0.6944 - dense_1_accuracy_7: 0.6729 - dense_1_accuracy_8: 0.6632 - dense_1_accuracy_9: 0.6632 - dense_1_loss: 0.0000e+00 - loss: 37.7424\n",
      "Epoch 8/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - dense_1_accuracy: 0.6743 - dense_1_accuracy_1: 0.6417 - dense_1_accuracy_10: 0.5986 - dense_1_accuracy_11: 0.6736 - dense_1_accuracy_12: 0.5431 - dense_1_accuracy_13: 0.5535 - dense_1_accuracy_14: 0.5972 - dense_1_accuracy_15: 0.5653 - dense_1_accuracy_16: 0.4451 - dense_1_accuracy_17: 0.5229 - dense_1_accuracy_18: 0.4465 - dense_1_accuracy_19: 0.4361 - dense_1_accuracy_2: 0.6521 - dense_1_accuracy_20: 0.5319 - dense_1_accuracy_21: 0.4785 - dense_1_accuracy_22: 0.4347 - dense_1_accuracy_23: 0.3806 - dense_1_accuracy_24: 0.4139 - dense_1_accuracy_25: 0.4236 - dense_1_accuracy_26: 0.4882 - dense_1_accuracy_27: 0.2396 - dense_1_accuracy_28: 0.4785 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6417 - dense_1_accuracy_4: 0.6312 - dense_1_accuracy_5: 0.6417 - dense_1_accuracy_6: 0.6632 - dense_1_accuracy_7: 0.6528 - dense_1_accuracy_8: 0.6417 - dense_1_accuracy_9: 0.6521 - dense_1_loss: 0.0000e+00 - loss: 38.1472\n",
      "Epoch 9/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - dense_1_accuracy: 0.6743 - dense_1_accuracy_1: 0.6306 - dense_1_accuracy_10: 0.6201 - dense_1_accuracy_11: 0.6417 - dense_1_accuracy_12: 0.5326 - dense_1_accuracy_13: 0.5437 - dense_1_accuracy_14: 0.5653 - dense_1_accuracy_15: 0.5118 - dense_1_accuracy_16: 0.4674 - dense_1_accuracy_17: 0.5444 - dense_1_accuracy_18: 0.4465 - dense_1_accuracy_19: 0.5111 - dense_1_accuracy_2: 0.6312 - dense_1_accuracy_20: 0.4778 - dense_1_accuracy_21: 0.4125 - dense_1_accuracy_22: 0.4562 - dense_1_accuracy_23: 0.3583 - dense_1_accuracy_24: 0.4250 - dense_1_accuracy_25: 0.3583 - dense_1_accuracy_26: 0.4139 - dense_1_accuracy_27: 0.1951 - dense_1_accuracy_28: 0.6521 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6312 - dense_1_accuracy_4: 0.6403 - dense_1_accuracy_5: 0.6528 - dense_1_accuracy_6: 0.6417 - dense_1_accuracy_7: 0.6632 - dense_1_accuracy_8: 0.6514 - dense_1_accuracy_9: 0.6312 - dense_1_loss: 0.0000e+00 - loss: 37.8779\n",
      "Epoch 10/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - dense_1_accuracy: 0.6951 - dense_1_accuracy_1: 0.6410 - dense_1_accuracy_10: 0.6194 - dense_1_accuracy_11: 0.6410 - dense_1_accuracy_12: 0.5437 - dense_1_accuracy_13: 0.6181 - dense_1_accuracy_14: 0.6396 - dense_1_accuracy_15: 0.5868 - dense_1_accuracy_16: 0.4667 - dense_1_accuracy_17: 0.6306 - dense_1_accuracy_18: 0.4778 - dense_1_accuracy_19: 0.5528 - dense_1_accuracy_2: 0.6201 - dense_1_accuracy_20: 0.5208 - dense_1_accuracy_21: 0.5104 - dense_1_accuracy_22: 0.5319 - dense_1_accuracy_23: 0.3701 - dense_1_accuracy_24: 0.5431 - dense_1_accuracy_25: 0.4125 - dense_1_accuracy_26: 0.4347 - dense_1_accuracy_27: 0.2708 - dense_1_accuracy_28: 0.3597 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6410 - dense_1_accuracy_4: 0.6514 - dense_1_accuracy_5: 0.6521 - dense_1_accuracy_6: 0.6201 - dense_1_accuracy_7: 0.6521 - dense_1_accuracy_8: 0.6201 - dense_1_accuracy_9: 0.6521 - dense_1_loss: 0.0000e+00 - loss: 37.8932\n",
      "Epoch 11/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - dense_1_accuracy: 0.6639 - dense_1_accuracy_1: 0.6201 - dense_1_accuracy_10: 0.6097 - dense_1_accuracy_11: 0.6632 - dense_1_accuracy_12: 0.5542 - dense_1_accuracy_13: 0.6083 - dense_1_accuracy_14: 0.5750 - dense_1_accuracy_15: 0.6083 - dense_1_accuracy_16: 0.4667 - dense_1_accuracy_17: 0.5868 - dense_1_accuracy_18: 0.5431 - dense_1_accuracy_19: 0.4896 - dense_1_accuracy_2: 0.6097 - dense_1_accuracy_20: 0.5104 - dense_1_accuracy_21: 0.4035 - dense_1_accuracy_22: 0.4778 - dense_1_accuracy_23: 0.4132 - dense_1_accuracy_24: 0.4347 - dense_1_accuracy_25: 0.3917 - dense_1_accuracy_26: 0.3035 - dense_1_accuracy_27: 0.2174 - dense_1_accuracy_28: 0.6528 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6417 - dense_1_accuracy_4: 0.6417 - dense_1_accuracy_5: 0.6306 - dense_1_accuracy_6: 0.6201 - dense_1_accuracy_7: 0.6736 - dense_1_accuracy_8: 0.6208 - dense_1_accuracy_9: 0.6410 - dense_1_loss: 0.0000e+00 - loss: 37.8861\n",
      "Epoch 12/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - dense_1_accuracy: 0.6743 - dense_1_accuracy_1: 0.6625 - dense_1_accuracy_10: 0.6514 - dense_1_accuracy_11: 0.6736 - dense_1_accuracy_12: 0.5639 - dense_1_accuracy_13: 0.5757 - dense_1_accuracy_14: 0.5444 - dense_1_accuracy_15: 0.5854 - dense_1_accuracy_16: 0.4465 - dense_1_accuracy_17: 0.6417 - dense_1_accuracy_18: 0.5535 - dense_1_accuracy_19: 0.4882 - dense_1_accuracy_2: 0.6729 - dense_1_accuracy_20: 0.5097 - dense_1_accuracy_21: 0.5437 - dense_1_accuracy_22: 0.5326 - dense_1_accuracy_23: 0.3806 - dense_1_accuracy_24: 0.5535 - dense_1_accuracy_25: 0.4007 - dense_1_accuracy_26: 0.3792 - dense_1_accuracy_27: 0.2729 - dense_1_accuracy_28: 0.5208 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6514 - dense_1_accuracy_4: 0.6410 - dense_1_accuracy_5: 0.6625 - dense_1_accuracy_6: 0.6729 - dense_1_accuracy_7: 0.6410 - dense_1_accuracy_8: 0.6194 - dense_1_accuracy_9: 0.6618 - dense_1_loss: 0.0000e+00 - loss: 37.0451\n",
      "Epoch 13/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - dense_1_accuracy: 0.7056 - dense_1_accuracy_1: 0.6937 - dense_1_accuracy_10: 0.6403 - dense_1_accuracy_11: 0.6611 - dense_1_accuracy_12: 0.5535 - dense_1_accuracy_13: 0.5750 - dense_1_accuracy_14: 0.5868 - dense_1_accuracy_15: 0.5965 - dense_1_accuracy_16: 0.4986 - dense_1_accuracy_17: 0.6299 - dense_1_accuracy_18: 0.5528 - dense_1_accuracy_19: 0.4451 - dense_1_accuracy_2: 0.6514 - dense_1_accuracy_20: 0.5319 - dense_1_accuracy_21: 0.5201 - dense_1_accuracy_22: 0.6069 - dense_1_accuracy_23: 0.3903 - dense_1_accuracy_24: 0.5076 - dense_1_accuracy_25: 0.4014 - dense_1_accuracy_26: 0.4653 - dense_1_accuracy_27: 0.2826 - dense_1_accuracy_28: 0.5014 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6507 - dense_1_accuracy_4: 0.6618 - dense_1_accuracy_5: 0.6937 - dense_1_accuracy_6: 0.6840 - dense_1_accuracy_7: 0.7056 - dense_1_accuracy_8: 0.6847 - dense_1_accuracy_9: 0.6618 - dense_1_loss: 0.0000e+00 - loss: 36.9024\n",
      "Epoch 14/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - dense_1_accuracy: 0.6639 - dense_1_accuracy_1: 0.6625 - dense_1_accuracy_10: 0.6292 - dense_1_accuracy_11: 0.6306 - dense_1_accuracy_12: 0.5333 - dense_1_accuracy_13: 0.6076 - dense_1_accuracy_14: 0.6090 - dense_1_accuracy_15: 0.5972 - dense_1_accuracy_16: 0.3806 - dense_1_accuracy_17: 0.5542 - dense_1_accuracy_18: 0.4882 - dense_1_accuracy_19: 0.5000 - dense_1_accuracy_2: 0.6410 - dense_1_accuracy_20: 0.5097 - dense_1_accuracy_21: 0.4771 - dense_1_accuracy_22: 0.5000 - dense_1_accuracy_23: 0.3903 - dense_1_accuracy_24: 0.4014 - dense_1_accuracy_25: 0.3694 - dense_1_accuracy_26: 0.3910 - dense_1_accuracy_27: 0.3042 - dense_1_accuracy_28: 0.5764 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6625 - dense_1_accuracy_4: 0.6514 - dense_1_accuracy_5: 0.6514 - dense_1_accuracy_6: 0.6625 - dense_1_accuracy_7: 0.6729 - dense_1_accuracy_8: 0.6410 - dense_1_accuracy_9: 0.6618 - dense_1_loss: 0.0000e+00 - loss: 38.2614\n",
      "Epoch 15/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - dense_1_accuracy: 0.6847 - dense_1_accuracy_1: 0.6625 - dense_1_accuracy_10: 0.6306 - dense_1_accuracy_11: 0.6729 - dense_1_accuracy_12: 0.5222 - dense_1_accuracy_13: 0.5854 - dense_1_accuracy_14: 0.5875 - dense_1_accuracy_15: 0.6083 - dense_1_accuracy_16: 0.5000 - dense_1_accuracy_17: 0.5653 - dense_1_accuracy_18: 0.4889 - dense_1_accuracy_19: 0.5326 - dense_1_accuracy_2: 0.6417 - dense_1_accuracy_20: 0.5215 - dense_1_accuracy_21: 0.4896 - dense_1_accuracy_22: 0.5431 - dense_1_accuracy_23: 0.3583 - dense_1_accuracy_24: 0.4465 - dense_1_accuracy_25: 0.4458 - dense_1_accuracy_26: 0.4465 - dense_1_accuracy_27: 0.3910 - dense_1_accuracy_28: 0.6639 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6521 - dense_1_accuracy_4: 0.6625 - dense_1_accuracy_5: 0.6632 - dense_1_accuracy_6: 0.6632 - dense_1_accuracy_7: 0.6521 - dense_1_accuracy_8: 0.6514 - dense_1_accuracy_9: 0.6514 - dense_1_loss: 0.0000e+00 - loss: 37.1501\n",
      "Epoch 16/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - dense_1_accuracy: 0.6535 - dense_1_accuracy_1: 0.5993 - dense_1_accuracy_10: 0.5875 - dense_1_accuracy_11: 0.6319 - dense_1_accuracy_12: 0.5222 - dense_1_accuracy_13: 0.5333 - dense_1_accuracy_14: 0.5229 - dense_1_accuracy_15: 0.5444 - dense_1_accuracy_16: 0.4903 - dense_1_accuracy_17: 0.5326 - dense_1_accuracy_18: 0.4785 - dense_1_accuracy_19: 0.5326 - dense_1_accuracy_2: 0.5986 - dense_1_accuracy_20: 0.5444 - dense_1_accuracy_21: 0.4257 - dense_1_accuracy_22: 0.4451 - dense_1_accuracy_23: 0.3375 - dense_1_accuracy_24: 0.4674 - dense_1_accuracy_25: 0.4236 - dense_1_accuracy_26: 0.4444 - dense_1_accuracy_27: 0.2181 - dense_1_accuracy_28: 0.6188 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6528 - dense_1_accuracy_4: 0.6097 - dense_1_accuracy_5: 0.6319 - dense_1_accuracy_6: 0.6424 - dense_1_accuracy_7: 0.6417 - dense_1_accuracy_8: 0.6417 - dense_1_accuracy_9: 0.6201 - dense_1_loss: 0.0000e+00 - loss: 38.2847\n",
      "Epoch 17/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - dense_1_accuracy: 0.6743 - dense_1_accuracy_1: 0.6312 - dense_1_accuracy_10: 0.5771 - dense_1_accuracy_11: 0.6417 - dense_1_accuracy_12: 0.5229 - dense_1_accuracy_13: 0.5229 - dense_1_accuracy_14: 0.5444 - dense_1_accuracy_15: 0.5868 - dense_1_accuracy_16: 0.4569 - dense_1_accuracy_17: 0.4910 - dense_1_accuracy_18: 0.4576 - dense_1_accuracy_19: 0.5542 - dense_1_accuracy_2: 0.6312 - dense_1_accuracy_20: 0.5660 - dense_1_accuracy_21: 0.4028 - dense_1_accuracy_22: 0.4889 - dense_1_accuracy_23: 0.3708 - dense_1_accuracy_24: 0.4681 - dense_1_accuracy_25: 0.3917 - dense_1_accuracy_26: 0.3694 - dense_1_accuracy_27: 0.2819 - dense_1_accuracy_28: 0.6188 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6417 - dense_1_accuracy_4: 0.6312 - dense_1_accuracy_5: 0.6306 - dense_1_accuracy_6: 0.6312 - dense_1_accuracy_7: 0.6090 - dense_1_accuracy_8: 0.6424 - dense_1_accuracy_9: 0.6417 - dense_1_loss: 0.0000e+00 - loss: 38.5951\n",
      "Epoch 18/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - dense_1_accuracy: 0.6847 - dense_1_accuracy_1: 0.6521 - dense_1_accuracy_10: 0.6306 - dense_1_accuracy_11: 0.6521 - dense_1_accuracy_12: 0.4896 - dense_1_accuracy_13: 0.5868 - dense_1_accuracy_14: 0.6083 - dense_1_accuracy_15: 0.5653 - dense_1_accuracy_16: 0.4569 - dense_1_accuracy_17: 0.5771 - dense_1_accuracy_18: 0.5319 - dense_1_accuracy_19: 0.5208 - dense_1_accuracy_2: 0.6521 - dense_1_accuracy_20: 0.5535 - dense_1_accuracy_21: 0.4778 - dense_1_accuracy_22: 0.4799 - dense_1_accuracy_23: 0.4222 - dense_1_accuracy_24: 0.4347 - dense_1_accuracy_25: 0.3153 - dense_1_accuracy_26: 0.3806 - dense_1_accuracy_27: 0.3049 - dense_1_accuracy_28: 0.6306 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6521 - dense_1_accuracy_4: 0.6521 - dense_1_accuracy_5: 0.6417 - dense_1_accuracy_6: 0.6528 - dense_1_accuracy_7: 0.6201 - dense_1_accuracy_8: 0.6528 - dense_1_accuracy_9: 0.6632 - dense_1_loss: 0.0000e+00 - loss: 37.4933\n",
      "Epoch 19/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - dense_1_accuracy: 0.7160 - dense_1_accuracy_1: 0.6729 - dense_1_accuracy_10: 0.5979 - dense_1_accuracy_11: 0.6944 - dense_1_accuracy_12: 0.5972 - dense_1_accuracy_13: 0.5528 - dense_1_accuracy_14: 0.6069 - dense_1_accuracy_15: 0.6299 - dense_1_accuracy_16: 0.4458 - dense_1_accuracy_17: 0.6514 - dense_1_accuracy_18: 0.5632 - dense_1_accuracy_19: 0.4660 - dense_1_accuracy_2: 0.6729 - dense_1_accuracy_20: 0.6396 - dense_1_accuracy_21: 0.4875 - dense_1_accuracy_22: 0.4896 - dense_1_accuracy_23: 0.4549 - dense_1_accuracy_24: 0.5535 - dense_1_accuracy_25: 0.4771 - dense_1_accuracy_26: 0.4562 - dense_1_accuracy_27: 0.2819 - dense_1_accuracy_28: 0.5965 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6833 - dense_1_accuracy_4: 0.6188 - dense_1_accuracy_5: 0.6618 - dense_1_accuracy_6: 0.6625 - dense_1_accuracy_7: 0.6833 - dense_1_accuracy_8: 0.6306 - dense_1_accuracy_9: 0.6292 - dense_1_loss: 0.0000e+00 - loss: 37.0771\n",
      "Epoch 20/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - dense_1_accuracy: 0.6743 - dense_1_accuracy_1: 0.6521 - dense_1_accuracy_10: 0.6299 - dense_1_accuracy_11: 0.6424 - dense_1_accuracy_12: 0.5542 - dense_1_accuracy_13: 0.5764 - dense_1_accuracy_14: 0.6083 - dense_1_accuracy_15: 0.5750 - dense_1_accuracy_16: 0.4132 - dense_1_accuracy_17: 0.6076 - dense_1_accuracy_18: 0.4556 - dense_1_accuracy_19: 0.5312 - dense_1_accuracy_2: 0.6417 - dense_1_accuracy_20: 0.5208 - dense_1_accuracy_21: 0.4354 - dense_1_accuracy_22: 0.5201 - dense_1_accuracy_23: 0.3257 - dense_1_accuracy_24: 0.4451 - dense_1_accuracy_25: 0.4444 - dense_1_accuracy_26: 0.3479 - dense_1_accuracy_27: 0.2611 - dense_1_accuracy_28: 0.6833 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6625 - dense_1_accuracy_4: 0.6194 - dense_1_accuracy_5: 0.6632 - dense_1_accuracy_6: 0.6632 - dense_1_accuracy_7: 0.6736 - dense_1_accuracy_8: 0.6521 - dense_1_accuracy_9: 0.6201 - dense_1_loss: 0.0000e+00 - loss: 38.0150\n",
      "Epoch 21/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - dense_1_accuracy: 0.6743 - dense_1_accuracy_1: 0.6521 - dense_1_accuracy_10: 0.6188 - dense_1_accuracy_11: 0.6097 - dense_1_accuracy_12: 0.5542 - dense_1_accuracy_13: 0.5326 - dense_1_accuracy_14: 0.5861 - dense_1_accuracy_15: 0.5986 - dense_1_accuracy_16: 0.5000 - dense_1_accuracy_17: 0.6410 - dense_1_accuracy_18: 0.4674 - dense_1_accuracy_19: 0.5639 - dense_1_accuracy_2: 0.6410 - dense_1_accuracy_20: 0.5431 - dense_1_accuracy_21: 0.5757 - dense_1_accuracy_22: 0.4778 - dense_1_accuracy_23: 0.3590 - dense_1_accuracy_24: 0.5201 - dense_1_accuracy_25: 0.4562 - dense_1_accuracy_26: 0.3903 - dense_1_accuracy_27: 0.2285 - dense_1_accuracy_28: 0.5208 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6625 - dense_1_accuracy_4: 0.6097 - dense_1_accuracy_5: 0.6417 - dense_1_accuracy_6: 0.6736 - dense_1_accuracy_7: 0.6521 - dense_1_accuracy_8: 0.6306 - dense_1_accuracy_9: 0.6090 - dense_1_loss: 0.0000e+00 - loss: 38.6646\n",
      "Epoch 22/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - dense_1_accuracy: 0.6535 - dense_1_accuracy_1: 0.6104 - dense_1_accuracy_10: 0.5556 - dense_1_accuracy_11: 0.5653 - dense_1_accuracy_12: 0.5222 - dense_1_accuracy_13: 0.5125 - dense_1_accuracy_14: 0.5007 - dense_1_accuracy_15: 0.5118 - dense_1_accuracy_16: 0.4132 - dense_1_accuracy_17: 0.5556 - dense_1_accuracy_18: 0.4896 - dense_1_accuracy_19: 0.5118 - dense_1_accuracy_2: 0.6097 - dense_1_accuracy_20: 0.4465 - dense_1_accuracy_21: 0.4889 - dense_1_accuracy_22: 0.4889 - dense_1_accuracy_23: 0.3694 - dense_1_accuracy_24: 0.4556 - dense_1_accuracy_25: 0.4021 - dense_1_accuracy_26: 0.3472 - dense_1_accuracy_27: 0.3257 - dense_1_accuracy_28: 0.5535 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6104 - dense_1_accuracy_4: 0.6424 - dense_1_accuracy_5: 0.6000 - dense_1_accuracy_6: 0.6319 - dense_1_accuracy_7: 0.6208 - dense_1_accuracy_8: 0.5986 - dense_1_accuracy_9: 0.5896 - dense_1_loss: 0.0000e+00 - loss: 39.5757\n",
      "Epoch 23/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - dense_1_accuracy: 0.7056 - dense_1_accuracy_1: 0.6937 - dense_1_accuracy_10: 0.6299 - dense_1_accuracy_11: 0.7042 - dense_1_accuracy_12: 0.5646 - dense_1_accuracy_13: 0.5111 - dense_1_accuracy_14: 0.5972 - dense_1_accuracy_15: 0.6285 - dense_1_accuracy_16: 0.4667 - dense_1_accuracy_17: 0.5646 - dense_1_accuracy_18: 0.5312 - dense_1_accuracy_19: 0.4562 - dense_1_accuracy_2: 0.6826 - dense_1_accuracy_20: 0.5312 - dense_1_accuracy_21: 0.3153 - dense_1_accuracy_22: 0.4451 - dense_1_accuracy_23: 0.4125 - dense_1_accuracy_24: 0.4333 - dense_1_accuracy_25: 0.3472 - dense_1_accuracy_26: 0.3257 - dense_1_accuracy_27: 0.2069 - dense_1_accuracy_28: 0.5854 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6625 - dense_1_accuracy_4: 0.6833 - dense_1_accuracy_5: 0.6833 - dense_1_accuracy_6: 0.6417 - dense_1_accuracy_7: 0.6403 - dense_1_accuracy_8: 0.6417 - dense_1_accuracy_9: 0.6722 - dense_1_loss: 0.0000e+00 - loss: 38.1189\n",
      "Epoch 24/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - dense_1_accuracy: 0.6639 - dense_1_accuracy_1: 0.6424 - dense_1_accuracy_10: 0.6076 - dense_1_accuracy_11: 0.5882 - dense_1_accuracy_12: 0.4889 - dense_1_accuracy_13: 0.4347 - dense_1_accuracy_14: 0.5750 - dense_1_accuracy_15: 0.5007 - dense_1_accuracy_16: 0.4347 - dense_1_accuracy_17: 0.5208 - dense_1_accuracy_18: 0.3799 - dense_1_accuracy_19: 0.3812 - dense_1_accuracy_2: 0.6312 - dense_1_accuracy_20: 0.5104 - dense_1_accuracy_21: 0.4021 - dense_1_accuracy_22: 0.3257 - dense_1_accuracy_23: 0.3375 - dense_1_accuracy_24: 0.3597 - dense_1_accuracy_25: 0.2819 - dense_1_accuracy_26: 0.2938 - dense_1_accuracy_27: 0.1847 - dense_1_accuracy_28: 0.5014 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6201 - dense_1_accuracy_4: 0.5993 - dense_1_accuracy_5: 0.6201 - dense_1_accuracy_6: 0.6528 - dense_1_accuracy_7: 0.6632 - dense_1_accuracy_8: 0.6632 - dense_1_accuracy_9: 0.6090 - dense_1_loss: 0.0000e+00 - loss: 41.5326\n",
      "Epoch 25/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - dense_1_accuracy: 0.6847 - dense_1_accuracy_1: 0.6306 - dense_1_accuracy_10: 0.5972 - dense_1_accuracy_11: 0.6410 - dense_1_accuracy_12: 0.4785 - dense_1_accuracy_13: 0.4785 - dense_1_accuracy_14: 0.5229 - dense_1_accuracy_15: 0.5319 - dense_1_accuracy_16: 0.4667 - dense_1_accuracy_17: 0.5000 - dense_1_accuracy_18: 0.4556 - dense_1_accuracy_19: 0.4229 - dense_1_accuracy_2: 0.6306 - dense_1_accuracy_20: 0.3917 - dense_1_accuracy_21: 0.3375 - dense_1_accuracy_22: 0.3688 - dense_1_accuracy_23: 0.2604 - dense_1_accuracy_24: 0.3799 - dense_1_accuracy_25: 0.2618 - dense_1_accuracy_26: 0.3028 - dense_1_accuracy_27: 0.2722 - dense_1_accuracy_28: 0.6076 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6514 - dense_1_accuracy_4: 0.6292 - dense_1_accuracy_5: 0.6417 - dense_1_accuracy_6: 0.6736 - dense_1_accuracy_7: 0.6410 - dense_1_accuracy_8: 0.6299 - dense_1_accuracy_9: 0.6194 - dense_1_loss: 0.0000e+00 - loss: 39.5381\n",
      "Epoch 26/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - dense_1_accuracy: 0.6743 - dense_1_accuracy_1: 0.6312 - dense_1_accuracy_10: 0.5764 - dense_1_accuracy_11: 0.6208 - dense_1_accuracy_12: 0.5319 - dense_1_accuracy_13: 0.5215 - dense_1_accuracy_14: 0.5215 - dense_1_accuracy_15: 0.5549 - dense_1_accuracy_16: 0.4549 - dense_1_accuracy_17: 0.5979 - dense_1_accuracy_18: 0.3694 - dense_1_accuracy_19: 0.4111 - dense_1_accuracy_2: 0.6312 - dense_1_accuracy_20: 0.5208 - dense_1_accuracy_21: 0.3924 - dense_1_accuracy_22: 0.3472 - dense_1_accuracy_23: 0.2500 - dense_1_accuracy_24: 0.4118 - dense_1_accuracy_25: 0.3688 - dense_1_accuracy_26: 0.3153 - dense_1_accuracy_27: 0.2826 - dense_1_accuracy_28: 0.4882 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6306 - dense_1_accuracy_4: 0.6743 - dense_1_accuracy_5: 0.6312 - dense_1_accuracy_6: 0.6097 - dense_1_accuracy_7: 0.6424 - dense_1_accuracy_8: 0.6729 - dense_1_accuracy_9: 0.5563 - dense_1_loss: 0.0000e+00 - loss: 39.4028\n",
      "Epoch 27/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - dense_1_accuracy: 0.7160 - dense_1_accuracy_1: 0.6729 - dense_1_accuracy_10: 0.6188 - dense_1_accuracy_11: 0.6194 - dense_1_accuracy_12: 0.5431 - dense_1_accuracy_13: 0.4875 - dense_1_accuracy_14: 0.5979 - dense_1_accuracy_15: 0.5535 - dense_1_accuracy_16: 0.3799 - dense_1_accuracy_17: 0.6083 - dense_1_accuracy_18: 0.4132 - dense_1_accuracy_19: 0.4451 - dense_1_accuracy_2: 0.6410 - dense_1_accuracy_20: 0.4451 - dense_1_accuracy_21: 0.3903 - dense_1_accuracy_22: 0.4118 - dense_1_accuracy_23: 0.3153 - dense_1_accuracy_24: 0.2938 - dense_1_accuracy_25: 0.2931 - dense_1_accuracy_26: 0.3799 - dense_1_accuracy_27: 0.3153 - dense_1_accuracy_28: 0.5125 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6514 - dense_1_accuracy_4: 0.6514 - dense_1_accuracy_5: 0.6625 - dense_1_accuracy_6: 0.6417 - dense_1_accuracy_7: 0.6840 - dense_1_accuracy_8: 0.6618 - dense_1_accuracy_9: 0.6840 - dense_1_loss: 0.0000e+00 - loss: 39.0428\n",
      "Epoch 28/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - dense_1_accuracy: 0.6847 - dense_1_accuracy_1: 0.6521 - dense_1_accuracy_10: 0.5882 - dense_1_accuracy_11: 0.6417 - dense_1_accuracy_12: 0.5326 - dense_1_accuracy_13: 0.4451 - dense_1_accuracy_14: 0.5319 - dense_1_accuracy_15: 0.4562 - dense_1_accuracy_16: 0.3694 - dense_1_accuracy_17: 0.5319 - dense_1_accuracy_18: 0.4042 - dense_1_accuracy_19: 0.4139 - dense_1_accuracy_2: 0.6097 - dense_1_accuracy_20: 0.3708 - dense_1_accuracy_21: 0.3701 - dense_1_accuracy_22: 0.4035 - dense_1_accuracy_23: 0.2938 - dense_1_accuracy_24: 0.3160 - dense_1_accuracy_25: 0.2396 - dense_1_accuracy_26: 0.2743 - dense_1_accuracy_27: 0.1861 - dense_1_accuracy_28: 0.6083 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6417 - dense_1_accuracy_4: 0.6306 - dense_1_accuracy_5: 0.5993 - dense_1_accuracy_6: 0.6215 - dense_1_accuracy_7: 0.5986 - dense_1_accuracy_8: 0.6090 - dense_1_accuracy_9: 0.5993 - dense_1_loss: 0.0000e+00 - loss: 40.4573\n",
      "Epoch 29/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - dense_1_accuracy: 0.6847 - dense_1_accuracy_1: 0.6632 - dense_1_accuracy_10: 0.5437 - dense_1_accuracy_11: 0.5667 - dense_1_accuracy_12: 0.5215 - dense_1_accuracy_13: 0.4569 - dense_1_accuracy_14: 0.5326 - dense_1_accuracy_15: 0.4458 - dense_1_accuracy_16: 0.3278 - dense_1_accuracy_17: 0.4785 - dense_1_accuracy_18: 0.3826 - dense_1_accuracy_19: 0.3924 - dense_1_accuracy_2: 0.6319 - dense_1_accuracy_20: 0.3931 - dense_1_accuracy_21: 0.3590 - dense_1_accuracy_22: 0.4028 - dense_1_accuracy_23: 0.2618 - dense_1_accuracy_24: 0.3701 - dense_1_accuracy_25: 0.3257 - dense_1_accuracy_26: 0.3382 - dense_1_accuracy_27: 0.2278 - dense_1_accuracy_28: 0.5854 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6208 - dense_1_accuracy_4: 0.6625 - dense_1_accuracy_5: 0.5993 - dense_1_accuracy_6: 0.6424 - dense_1_accuracy_7: 0.6097 - dense_1_accuracy_8: 0.6306 - dense_1_accuracy_9: 0.5986 - dense_1_loss: 0.0000e+00 - loss: 42.3903\n",
      "Epoch 30/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - dense_1_accuracy: 0.6639 - dense_1_accuracy_1: 0.6312 - dense_1_accuracy_10: 0.5979 - dense_1_accuracy_11: 0.6632 - dense_1_accuracy_12: 0.5542 - dense_1_accuracy_13: 0.5215 - dense_1_accuracy_14: 0.5333 - dense_1_accuracy_15: 0.5326 - dense_1_accuracy_16: 0.4333 - dense_1_accuracy_17: 0.5111 - dense_1_accuracy_18: 0.4444 - dense_1_accuracy_19: 0.5431 - dense_1_accuracy_2: 0.6194 - dense_1_accuracy_20: 0.4236 - dense_1_accuracy_21: 0.4875 - dense_1_accuracy_22: 0.3590 - dense_1_accuracy_23: 0.3250 - dense_1_accuracy_24: 0.4347 - dense_1_accuracy_25: 0.3458 - dense_1_accuracy_26: 0.3146 - dense_1_accuracy_27: 0.2271 - dense_1_accuracy_28: 0.6312 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6417 - dense_1_accuracy_4: 0.5979 - dense_1_accuracy_5: 0.6306 - dense_1_accuracy_6: 0.6632 - dense_1_accuracy_7: 0.6306 - dense_1_accuracy_8: 0.6840 - dense_1_accuracy_9: 0.6090 - dense_1_loss: 0.0000e+00 - loss: 38.3946\n",
      "Epoch 31/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - dense_1_accuracy: 0.6639 - dense_1_accuracy_1: 0.6417 - dense_1_accuracy_10: 0.6083 - dense_1_accuracy_11: 0.5764 - dense_1_accuracy_12: 0.5431 - dense_1_accuracy_13: 0.5535 - dense_1_accuracy_14: 0.5312 - dense_1_accuracy_15: 0.4361 - dense_1_accuracy_16: 0.4229 - dense_1_accuracy_17: 0.5965 - dense_1_accuracy_18: 0.4889 - dense_1_accuracy_19: 0.3903 - dense_1_accuracy_2: 0.6417 - dense_1_accuracy_20: 0.4882 - dense_1_accuracy_21: 0.4236 - dense_1_accuracy_22: 0.3257 - dense_1_accuracy_23: 0.2715 - dense_1_accuracy_24: 0.3479 - dense_1_accuracy_25: 0.3035 - dense_1_accuracy_26: 0.2396 - dense_1_accuracy_27: 0.1736 - dense_1_accuracy_28: 0.5208 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6521 - dense_1_accuracy_4: 0.5882 - dense_1_accuracy_5: 0.5993 - dense_1_accuracy_6: 0.6528 - dense_1_accuracy_7: 0.6424 - dense_1_accuracy_8: 0.6632 - dense_1_accuracy_9: 0.6090 - dense_1_loss: 0.0000e+00 - loss: 40.7286\n",
      "Epoch 32/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - dense_1_accuracy: 0.6951 - dense_1_accuracy_1: 0.6514 - dense_1_accuracy_10: 0.6521 - dense_1_accuracy_11: 0.6840 - dense_1_accuracy_12: 0.5653 - dense_1_accuracy_13: 0.5000 - dense_1_accuracy_14: 0.5549 - dense_1_accuracy_15: 0.5868 - dense_1_accuracy_16: 0.4458 - dense_1_accuracy_17: 0.6194 - dense_1_accuracy_18: 0.5097 - dense_1_accuracy_19: 0.4444 - dense_1_accuracy_2: 0.6625 - dense_1_accuracy_20: 0.5104 - dense_1_accuracy_21: 0.5208 - dense_1_accuracy_22: 0.5201 - dense_1_accuracy_23: 0.3903 - dense_1_accuracy_24: 0.3903 - dense_1_accuracy_25: 0.3576 - dense_1_accuracy_26: 0.4340 - dense_1_accuracy_27: 0.3153 - dense_1_accuracy_28: 0.5104 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6410 - dense_1_accuracy_4: 0.6625 - dense_1_accuracy_5: 0.6618 - dense_1_accuracy_6: 0.6417 - dense_1_accuracy_7: 0.7049 - dense_1_accuracy_8: 0.6632 - dense_1_accuracy_9: 0.6410 - dense_1_loss: 0.0000e+00 - loss: 38.4105\n",
      "Epoch 33/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - dense_1_accuracy: 0.6743 - dense_1_accuracy_1: 0.6201 - dense_1_accuracy_10: 0.5444 - dense_1_accuracy_11: 0.6201 - dense_1_accuracy_12: 0.4465 - dense_1_accuracy_13: 0.4681 - dense_1_accuracy_14: 0.5333 - dense_1_accuracy_15: 0.4785 - dense_1_accuracy_16: 0.3694 - dense_1_accuracy_17: 0.4347 - dense_1_accuracy_18: 0.4028 - dense_1_accuracy_19: 0.4569 - dense_1_accuracy_2: 0.6312 - dense_1_accuracy_20: 0.4028 - dense_1_accuracy_21: 0.3375 - dense_1_accuracy_22: 0.4458 - dense_1_accuracy_23: 0.2715 - dense_1_accuracy_24: 0.3264 - dense_1_accuracy_25: 0.2819 - dense_1_accuracy_26: 0.2819 - dense_1_accuracy_27: 0.2396 - dense_1_accuracy_28: 0.5201 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6632 - dense_1_accuracy_4: 0.6840 - dense_1_accuracy_5: 0.6312 - dense_1_accuracy_6: 0.6208 - dense_1_accuracy_7: 0.6632 - dense_1_accuracy_8: 0.6417 - dense_1_accuracy_9: 0.5764 - dense_1_loss: 0.0000e+00 - loss: 41.1774 \n",
      "Epoch 34/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - dense_1_accuracy: 0.6736 - dense_1_accuracy_1: 0.6521 - dense_1_accuracy_10: 0.5757 - dense_1_accuracy_11: 0.6299 - dense_1_accuracy_12: 0.5215 - dense_1_accuracy_13: 0.4778 - dense_1_accuracy_14: 0.5431 - dense_1_accuracy_15: 0.5000 - dense_1_accuracy_16: 0.4340 - dense_1_accuracy_17: 0.4889 - dense_1_accuracy_18: 0.4451 - dense_1_accuracy_19: 0.5104 - dense_1_accuracy_2: 0.6521 - dense_1_accuracy_20: 0.3924 - dense_1_accuracy_21: 0.3681 - dense_1_accuracy_22: 0.3785 - dense_1_accuracy_23: 0.2924 - dense_1_accuracy_24: 0.4229 - dense_1_accuracy_25: 0.3354 - dense_1_accuracy_26: 0.3583 - dense_1_accuracy_27: 0.2181 - dense_1_accuracy_28: 0.5000 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6847 - dense_1_accuracy_4: 0.6090 - dense_1_accuracy_5: 0.6521 - dense_1_accuracy_6: 0.6632 - dense_1_accuracy_7: 0.6312 - dense_1_accuracy_8: 0.6424 - dense_1_accuracy_9: 0.5979 - dense_1_loss: 0.0000e+00 - loss: 40.3482\n",
      "Epoch 35/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - dense_1_accuracy: 0.6431 - dense_1_accuracy_1: 0.6208 - dense_1_accuracy_10: 0.5972 - dense_1_accuracy_11: 0.5437 - dense_1_accuracy_12: 0.4340 - dense_1_accuracy_13: 0.4451 - dense_1_accuracy_14: 0.5104 - dense_1_accuracy_15: 0.4889 - dense_1_accuracy_16: 0.3590 - dense_1_accuracy_17: 0.4674 - dense_1_accuracy_18: 0.4132 - dense_1_accuracy_19: 0.4333 - dense_1_accuracy_2: 0.6097 - dense_1_accuracy_20: 0.3799 - dense_1_accuracy_21: 0.2389 - dense_1_accuracy_22: 0.3257 - dense_1_accuracy_23: 0.1951 - dense_1_accuracy_24: 0.3701 - dense_1_accuracy_25: 0.2493 - dense_1_accuracy_26: 0.3049 - dense_1_accuracy_27: 0.2062 - dense_1_accuracy_28: 0.5542 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6201 - dense_1_accuracy_4: 0.6201 - dense_1_accuracy_5: 0.6208 - dense_1_accuracy_6: 0.6632 - dense_1_accuracy_7: 0.5771 - dense_1_accuracy_8: 0.6417 - dense_1_accuracy_9: 0.6097 - dense_1_loss: 0.0000e+00 - loss: 41.3552\n",
      "Epoch 36/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - dense_1_accuracy: 0.6847 - dense_1_accuracy_1: 0.6521 - dense_1_accuracy_10: 0.6090 - dense_1_accuracy_11: 0.6188 - dense_1_accuracy_12: 0.5104 - dense_1_accuracy_13: 0.5444 - dense_1_accuracy_14: 0.3826 - dense_1_accuracy_15: 0.5021 - dense_1_accuracy_16: 0.3590 - dense_1_accuracy_17: 0.5097 - dense_1_accuracy_18: 0.4785 - dense_1_accuracy_19: 0.3917 - dense_1_accuracy_2: 0.6410 - dense_1_accuracy_20: 0.4236 - dense_1_accuracy_21: 0.4340 - dense_1_accuracy_22: 0.4347 - dense_1_accuracy_23: 0.3146 - dense_1_accuracy_24: 0.4562 - dense_1_accuracy_25: 0.3257 - dense_1_accuracy_26: 0.2611 - dense_1_accuracy_27: 0.2715 - dense_1_accuracy_28: 0.5104 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6201 - dense_1_accuracy_4: 0.6625 - dense_1_accuracy_5: 0.6417 - dense_1_accuracy_6: 0.6410 - dense_1_accuracy_7: 0.6201 - dense_1_accuracy_8: 0.6514 - dense_1_accuracy_9: 0.6201 - dense_1_loss: 0.0000e+00 - loss: 39.2520\n",
      "Epoch 37/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - dense_1_accuracy: 0.6743 - dense_1_accuracy_1: 0.6417 - dense_1_accuracy_10: 0.5653 - dense_1_accuracy_11: 0.5979 - dense_1_accuracy_12: 0.4125 - dense_1_accuracy_13: 0.4785 - dense_1_accuracy_14: 0.4458 - dense_1_accuracy_15: 0.4681 - dense_1_accuracy_16: 0.3694 - dense_1_accuracy_17: 0.3479 - dense_1_accuracy_18: 0.3035 - dense_1_accuracy_19: 0.3264 - dense_1_accuracy_2: 0.6417 - dense_1_accuracy_20: 0.3479 - dense_1_accuracy_21: 0.3257 - dense_1_accuracy_22: 0.2944 - dense_1_accuracy_23: 0.2174 - dense_1_accuracy_24: 0.2722 - dense_1_accuracy_25: 0.2493 - dense_1_accuracy_26: 0.2715 - dense_1_accuracy_27: 0.1521 - dense_1_accuracy_28: 0.4132 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6639 - dense_1_accuracy_4: 0.6306 - dense_1_accuracy_5: 0.5986 - dense_1_accuracy_6: 0.6194 - dense_1_accuracy_7: 0.6528 - dense_1_accuracy_8: 0.6736 - dense_1_accuracy_9: 0.6201 - dense_1_loss: 0.0000e+00 - loss: 43.3813\n",
      "Epoch 38/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - dense_1_accuracy: 0.6743 - dense_1_accuracy_1: 0.6417 - dense_1_accuracy_10: 0.6410 - dense_1_accuracy_11: 0.6312 - dense_1_accuracy_12: 0.5444 - dense_1_accuracy_13: 0.5000 - dense_1_accuracy_14: 0.5986 - dense_1_accuracy_15: 0.5771 - dense_1_accuracy_16: 0.3924 - dense_1_accuracy_17: 0.5639 - dense_1_accuracy_18: 0.4458 - dense_1_accuracy_19: 0.4340 - dense_1_accuracy_2: 0.6521 - dense_1_accuracy_20: 0.4250 - dense_1_accuracy_21: 0.4674 - dense_1_accuracy_22: 0.4118 - dense_1_accuracy_23: 0.4444 - dense_1_accuracy_24: 0.4431 - dense_1_accuracy_25: 0.4118 - dense_1_accuracy_26: 0.3917 - dense_1_accuracy_27: 0.1854 - dense_1_accuracy_28: 0.6306 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6521 - dense_1_accuracy_4: 0.6521 - dense_1_accuracy_5: 0.6632 - dense_1_accuracy_6: 0.6625 - dense_1_accuracy_7: 0.6417 - dense_1_accuracy_8: 0.7056 - dense_1_accuracy_9: 0.6299 - dense_1_loss: 0.0000e+00 - loss: 38.6761\n",
      "Epoch 39/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - dense_1_accuracy: 0.6847 - dense_1_accuracy_1: 0.6521 - dense_1_accuracy_10: 0.6188 - dense_1_accuracy_11: 0.6410 - dense_1_accuracy_12: 0.5535 - dense_1_accuracy_13: 0.4340 - dense_1_accuracy_14: 0.5646 - dense_1_accuracy_15: 0.4347 - dense_1_accuracy_16: 0.3694 - dense_1_accuracy_17: 0.4785 - dense_1_accuracy_18: 0.4021 - dense_1_accuracy_19: 0.3264 - dense_1_accuracy_2: 0.6417 - dense_1_accuracy_20: 0.4021 - dense_1_accuracy_21: 0.4778 - dense_1_accuracy_22: 0.3153 - dense_1_accuracy_23: 0.3799 - dense_1_accuracy_24: 0.3167 - dense_1_accuracy_25: 0.2285 - dense_1_accuracy_26: 0.3264 - dense_1_accuracy_27: 0.2181 - dense_1_accuracy_28: 0.5090 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6521 - dense_1_accuracy_4: 0.6201 - dense_1_accuracy_5: 0.6736 - dense_1_accuracy_6: 0.6625 - dense_1_accuracy_7: 0.6306 - dense_1_accuracy_8: 0.6729 - dense_1_accuracy_9: 0.6194 - dense_1_loss: 0.0000e+00 - loss: 40.7824\n",
      "Epoch 40/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - dense_1_accuracy: 0.6847 - dense_1_accuracy_1: 0.6625 - dense_1_accuracy_10: 0.6194 - dense_1_accuracy_11: 0.5854 - dense_1_accuracy_12: 0.5111 - dense_1_accuracy_13: 0.4361 - dense_1_accuracy_14: 0.5326 - dense_1_accuracy_15: 0.5222 - dense_1_accuracy_16: 0.3056 - dense_1_accuracy_17: 0.4465 - dense_1_accuracy_18: 0.3486 - dense_1_accuracy_19: 0.4458 - dense_1_accuracy_2: 0.6625 - dense_1_accuracy_20: 0.3910 - dense_1_accuracy_21: 0.3583 - dense_1_accuracy_22: 0.3271 - dense_1_accuracy_23: 0.2069 - dense_1_accuracy_24: 0.3375 - dense_1_accuracy_25: 0.1854 - dense_1_accuracy_26: 0.2819 - dense_1_accuracy_27: 0.2604 - dense_1_accuracy_28: 0.3917 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6625 - dense_1_accuracy_4: 0.6625 - dense_1_accuracy_5: 0.6625 - dense_1_accuracy_6: 0.6299 - dense_1_accuracy_7: 0.6618 - dense_1_accuracy_8: 0.6306 - dense_1_accuracy_9: 0.6403 - dense_1_loss: 0.0000e+00 - loss: 42.1370\n",
      "Epoch 41/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - dense_1_accuracy: 0.6951 - dense_1_accuracy_1: 0.6729 - dense_1_accuracy_10: 0.5972 - dense_1_accuracy_11: 0.6514 - dense_1_accuracy_12: 0.5431 - dense_1_accuracy_13: 0.5542 - dense_1_accuracy_14: 0.5111 - dense_1_accuracy_15: 0.5215 - dense_1_accuracy_16: 0.4132 - dense_1_accuracy_17: 0.5326 - dense_1_accuracy_18: 0.4132 - dense_1_accuracy_19: 0.4236 - dense_1_accuracy_2: 0.6729 - dense_1_accuracy_20: 0.3806 - dense_1_accuracy_21: 0.4347 - dense_1_accuracy_22: 0.4021 - dense_1_accuracy_23: 0.3361 - dense_1_accuracy_24: 0.4236 - dense_1_accuracy_25: 0.3042 - dense_1_accuracy_26: 0.3576 - dense_1_accuracy_27: 0.2708 - dense_1_accuracy_28: 0.5000 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6625 - dense_1_accuracy_4: 0.6729 - dense_1_accuracy_5: 0.6729 - dense_1_accuracy_6: 0.6188 - dense_1_accuracy_7: 0.6840 - dense_1_accuracy_8: 0.6312 - dense_1_accuracy_9: 0.6083 - dense_1_loss: 0.0000e+00 - loss: 38.8829\n",
      "Epoch 42/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - dense_1_accuracy: 0.6535 - dense_1_accuracy_1: 0.5986 - dense_1_accuracy_10: 0.4896 - dense_1_accuracy_11: 0.6424 - dense_1_accuracy_12: 0.4889 - dense_1_accuracy_13: 0.4903 - dense_1_accuracy_14: 0.5660 - dense_1_accuracy_15: 0.5764 - dense_1_accuracy_16: 0.4451 - dense_1_accuracy_17: 0.5333 - dense_1_accuracy_18: 0.4139 - dense_1_accuracy_19: 0.4667 - dense_1_accuracy_2: 0.6201 - dense_1_accuracy_20: 0.4347 - dense_1_accuracy_21: 0.3701 - dense_1_accuracy_22: 0.4458 - dense_1_accuracy_23: 0.2618 - dense_1_accuracy_24: 0.3819 - dense_1_accuracy_25: 0.2604 - dense_1_accuracy_26: 0.3486 - dense_1_accuracy_27: 0.2174 - dense_1_accuracy_28: 0.5326 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.5882 - dense_1_accuracy_4: 0.6312 - dense_1_accuracy_5: 0.6208 - dense_1_accuracy_6: 0.5882 - dense_1_accuracy_7: 0.6097 - dense_1_accuracy_8: 0.5993 - dense_1_accuracy_9: 0.5660 - dense_1_loss: 0.0000e+00 - loss: 39.9871\n",
      "Epoch 43/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - dense_1_accuracy: 0.6535 - dense_1_accuracy_1: 0.5993 - dense_1_accuracy_10: 0.5667 - dense_1_accuracy_11: 0.6000 - dense_1_accuracy_12: 0.4910 - dense_1_accuracy_13: 0.4681 - dense_1_accuracy_14: 0.5875 - dense_1_accuracy_15: 0.5222 - dense_1_accuracy_16: 0.4458 - dense_1_accuracy_17: 0.5132 - dense_1_accuracy_18: 0.4250 - dense_1_accuracy_19: 0.4139 - dense_1_accuracy_2: 0.6104 - dense_1_accuracy_20: 0.3493 - dense_1_accuracy_21: 0.4236 - dense_1_accuracy_22: 0.3819 - dense_1_accuracy_23: 0.2938 - dense_1_accuracy_24: 0.4354 - dense_1_accuracy_25: 0.3500 - dense_1_accuracy_26: 0.3701 - dense_1_accuracy_27: 0.1861 - dense_1_accuracy_28: 0.5000 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6208 - dense_1_accuracy_4: 0.5986 - dense_1_accuracy_5: 0.6104 - dense_1_accuracy_6: 0.6208 - dense_1_accuracy_7: 0.6306 - dense_1_accuracy_8: 0.6312 - dense_1_accuracy_9: 0.5993 - dense_1_loss: 0.0000e+00 - loss: 40.9242\n",
      "Epoch 44/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - dense_1_accuracy: 0.6639 - dense_1_accuracy_1: 0.6312 - dense_1_accuracy_10: 0.5771 - dense_1_accuracy_11: 0.6208 - dense_1_accuracy_12: 0.5660 - dense_1_accuracy_13: 0.4569 - dense_1_accuracy_14: 0.6090 - dense_1_accuracy_15: 0.5014 - dense_1_accuracy_16: 0.4132 - dense_1_accuracy_17: 0.5326 - dense_1_accuracy_18: 0.3819 - dense_1_accuracy_19: 0.3812 - dense_1_accuracy_2: 0.6410 - dense_1_accuracy_20: 0.4694 - dense_1_accuracy_21: 0.4035 - dense_1_accuracy_22: 0.4021 - dense_1_accuracy_23: 0.1750 - dense_1_accuracy_24: 0.3694 - dense_1_accuracy_25: 0.3812 - dense_1_accuracy_26: 0.2514 - dense_1_accuracy_27: 0.2514 - dense_1_accuracy_28: 0.5979 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6104 - dense_1_accuracy_4: 0.6201 - dense_1_accuracy_5: 0.6528 - dense_1_accuracy_6: 0.6632 - dense_1_accuracy_7: 0.5993 - dense_1_accuracy_8: 0.6528 - dense_1_accuracy_9: 0.6097 - dense_1_loss: 0.0000e+00 - loss: 39.7172\n",
      "Epoch 45/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - dense_1_accuracy: 0.6840 - dense_1_accuracy_1: 0.6729 - dense_1_accuracy_10: 0.6507 - dense_1_accuracy_11: 0.6201 - dense_1_accuracy_12: 0.6181 - dense_1_accuracy_13: 0.5417 - dense_1_accuracy_14: 0.6507 - dense_1_accuracy_15: 0.6403 - dense_1_accuracy_16: 0.5090 - dense_1_accuracy_17: 0.6507 - dense_1_accuracy_18: 0.5111 - dense_1_accuracy_19: 0.4979 - dense_1_accuracy_2: 0.6403 - dense_1_accuracy_20: 0.5965 - dense_1_accuracy_21: 0.4993 - dense_1_accuracy_22: 0.4771 - dense_1_accuracy_23: 0.3694 - dense_1_accuracy_24: 0.4444 - dense_1_accuracy_25: 0.3146 - dense_1_accuracy_26: 0.3688 - dense_1_accuracy_27: 0.2382 - dense_1_accuracy_28: 0.4785 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6833 - dense_1_accuracy_4: 0.6514 - dense_1_accuracy_5: 0.6417 - dense_1_accuracy_6: 0.6937 - dense_1_accuracy_7: 0.6521 - dense_1_accuracy_8: 0.6944 - dense_1_accuracy_9: 0.6521 - dense_1_loss: 0.0000e+00 - loss: 36.8735\n",
      "Epoch 46/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - dense_1_accuracy: 0.6743 - dense_1_accuracy_1: 0.6521 - dense_1_accuracy_10: 0.6090 - dense_1_accuracy_11: 0.6625 - dense_1_accuracy_12: 0.5125 - dense_1_accuracy_13: 0.5118 - dense_1_accuracy_14: 0.6090 - dense_1_accuracy_15: 0.5660 - dense_1_accuracy_16: 0.4465 - dense_1_accuracy_17: 0.5986 - dense_1_accuracy_18: 0.5215 - dense_1_accuracy_19: 0.4792 - dense_1_accuracy_2: 0.6417 - dense_1_accuracy_20: 0.5437 - dense_1_accuracy_21: 0.4681 - dense_1_accuracy_22: 0.5431 - dense_1_accuracy_23: 0.4243 - dense_1_accuracy_24: 0.5000 - dense_1_accuracy_25: 0.3382 - dense_1_accuracy_26: 0.3375 - dense_1_accuracy_27: 0.2069 - dense_1_accuracy_28: 0.6840 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6194 - dense_1_accuracy_4: 0.6528 - dense_1_accuracy_5: 0.6521 - dense_1_accuracy_6: 0.6306 - dense_1_accuracy_7: 0.6632 - dense_1_accuracy_8: 0.6417 - dense_1_accuracy_9: 0.6201 - dense_1_loss: 0.0000e+00 - loss: 37.9798\n",
      "Epoch 47/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - dense_1_accuracy: 0.6847 - dense_1_accuracy_1: 0.6410 - dense_1_accuracy_10: 0.6299 - dense_1_accuracy_11: 0.6736 - dense_1_accuracy_12: 0.5861 - dense_1_accuracy_13: 0.5424 - dense_1_accuracy_14: 0.5868 - dense_1_accuracy_15: 0.5757 - dense_1_accuracy_16: 0.4437 - dense_1_accuracy_17: 0.5535 - dense_1_accuracy_18: 0.5528 - dense_1_accuracy_19: 0.5757 - dense_1_accuracy_2: 0.6194 - dense_1_accuracy_20: 0.5007 - dense_1_accuracy_21: 0.4771 - dense_1_accuracy_22: 0.5653 - dense_1_accuracy_23: 0.4667 - dense_1_accuracy_24: 0.5312 - dense_1_accuracy_25: 0.4882 - dense_1_accuracy_26: 0.3569 - dense_1_accuracy_27: 0.2722 - dense_1_accuracy_28: 0.7063 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6306 - dense_1_accuracy_4: 0.6410 - dense_1_accuracy_5: 0.6521 - dense_1_accuracy_6: 0.6625 - dense_1_accuracy_7: 0.6736 - dense_1_accuracy_8: 0.6833 - dense_1_accuracy_9: 0.6090 - dense_1_loss: 0.0000e+00 - loss: 35.7213\n",
      "Epoch 48/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - dense_1_accuracy: 0.6847 - dense_1_accuracy_1: 0.6521 - dense_1_accuracy_10: 0.6514 - dense_1_accuracy_11: 0.6528 - dense_1_accuracy_12: 0.4903 - dense_1_accuracy_13: 0.5535 - dense_1_accuracy_14: 0.5764 - dense_1_accuracy_15: 0.5437 - dense_1_accuracy_16: 0.4771 - dense_1_accuracy_17: 0.6410 - dense_1_accuracy_18: 0.4896 - dense_1_accuracy_19: 0.5097 - dense_1_accuracy_2: 0.6417 - dense_1_accuracy_20: 0.5104 - dense_1_accuracy_21: 0.5431 - dense_1_accuracy_22: 0.5535 - dense_1_accuracy_23: 0.3903 - dense_1_accuracy_24: 0.5208 - dense_1_accuracy_25: 0.3590 - dense_1_accuracy_26: 0.3153 - dense_1_accuracy_27: 0.3035 - dense_1_accuracy_28: 0.6521 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6417 - dense_1_accuracy_4: 0.6410 - dense_1_accuracy_5: 0.6312 - dense_1_accuracy_6: 0.6736 - dense_1_accuracy_7: 0.6840 - dense_1_accuracy_8: 0.6736 - dense_1_accuracy_9: 0.6299 - dense_1_loss: 0.0000e+00 - loss: 37.3367\n",
      "Epoch 49/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - dense_1_accuracy: 0.7056 - dense_1_accuracy_1: 0.6521 - dense_1_accuracy_10: 0.6201 - dense_1_accuracy_11: 0.6521 - dense_1_accuracy_12: 0.5861 - dense_1_accuracy_13: 0.5750 - dense_1_accuracy_14: 0.5660 - dense_1_accuracy_15: 0.6396 - dense_1_accuracy_16: 0.4889 - dense_1_accuracy_17: 0.6292 - dense_1_accuracy_18: 0.4896 - dense_1_accuracy_19: 0.5326 - dense_1_accuracy_2: 0.6090 - dense_1_accuracy_20: 0.5000 - dense_1_accuracy_21: 0.5757 - dense_1_accuracy_22: 0.4569 - dense_1_accuracy_23: 0.3583 - dense_1_accuracy_24: 0.5215 - dense_1_accuracy_25: 0.4465 - dense_1_accuracy_26: 0.3924 - dense_1_accuracy_27: 0.3042 - dense_1_accuracy_28: 0.6208 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6514 - dense_1_accuracy_4: 0.6417 - dense_1_accuracy_5: 0.6410 - dense_1_accuracy_6: 0.6521 - dense_1_accuracy_7: 0.6840 - dense_1_accuracy_8: 0.6528 - dense_1_accuracy_9: 0.6625 - dense_1_loss: 0.0000e+00 - loss: 36.6446\n",
      "Epoch 50/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - dense_1_accuracy: 0.6951 - dense_1_accuracy_1: 0.6410 - dense_1_accuracy_10: 0.6403 - dense_1_accuracy_11: 0.6625 - dense_1_accuracy_12: 0.6083 - dense_1_accuracy_13: 0.5535 - dense_1_accuracy_14: 0.5764 - dense_1_accuracy_15: 0.6083 - dense_1_accuracy_16: 0.5201 - dense_1_accuracy_17: 0.6410 - dense_1_accuracy_18: 0.5965 - dense_1_accuracy_19: 0.5632 - dense_1_accuracy_2: 0.6625 - dense_1_accuracy_20: 0.5965 - dense_1_accuracy_21: 0.5750 - dense_1_accuracy_22: 0.5757 - dense_1_accuracy_23: 0.4028 - dense_1_accuracy_24: 0.5528 - dense_1_accuracy_25: 0.5431 - dense_1_accuracy_26: 0.4549 - dense_1_accuracy_27: 0.3035 - dense_1_accuracy_28: 0.6528 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6618 - dense_1_accuracy_4: 0.6521 - dense_1_accuracy_5: 0.6625 - dense_1_accuracy_6: 0.6736 - dense_1_accuracy_7: 0.6840 - dense_1_accuracy_8: 0.6632 - dense_1_accuracy_9: 0.6729 - dense_1_loss: 0.0000e+00 - loss: 35.1902\n",
      "Epoch 51/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - dense_1_accuracy: 0.6840 - dense_1_accuracy_1: 0.6840 - dense_1_accuracy_10: 0.6076 - dense_1_accuracy_11: 0.6410 - dense_1_accuracy_12: 0.5854 - dense_1_accuracy_13: 0.5632 - dense_1_accuracy_14: 0.5965 - dense_1_accuracy_15: 0.5965 - dense_1_accuracy_16: 0.4458 - dense_1_accuracy_17: 0.6410 - dense_1_accuracy_18: 0.5424 - dense_1_accuracy_19: 0.5201 - dense_1_accuracy_2: 0.6625 - dense_1_accuracy_20: 0.5757 - dense_1_accuracy_21: 0.4882 - dense_1_accuracy_22: 0.5528 - dense_1_accuracy_23: 0.4340 - dense_1_accuracy_24: 0.4771 - dense_1_accuracy_25: 0.4132 - dense_1_accuracy_26: 0.4125 - dense_1_accuracy_27: 0.2278 - dense_1_accuracy_28: 0.6299 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6625 - dense_1_accuracy_4: 0.5986 - dense_1_accuracy_5: 0.6729 - dense_1_accuracy_6: 0.6840 - dense_1_accuracy_7: 0.6729 - dense_1_accuracy_8: 0.6521 - dense_1_accuracy_9: 0.6521 - dense_1_loss: 0.0000e+00 - loss: 36.7142\n",
      "Epoch 52/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - dense_1_accuracy: 0.6951 - dense_1_accuracy_1: 0.6306 - dense_1_accuracy_10: 0.6410 - dense_1_accuracy_11: 0.6417 - dense_1_accuracy_12: 0.5646 - dense_1_accuracy_13: 0.5535 - dense_1_accuracy_14: 0.5875 - dense_1_accuracy_15: 0.5979 - dense_1_accuracy_16: 0.4993 - dense_1_accuracy_17: 0.6076 - dense_1_accuracy_18: 0.5542 - dense_1_accuracy_19: 0.4896 - dense_1_accuracy_2: 0.6521 - dense_1_accuracy_20: 0.5868 - dense_1_accuracy_21: 0.5653 - dense_1_accuracy_22: 0.5222 - dense_1_accuracy_23: 0.4347 - dense_1_accuracy_24: 0.5535 - dense_1_accuracy_25: 0.4243 - dense_1_accuracy_26: 0.3264 - dense_1_accuracy_27: 0.2931 - dense_1_accuracy_28: 0.6958 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6410 - dense_1_accuracy_4: 0.5986 - dense_1_accuracy_5: 0.6625 - dense_1_accuracy_6: 0.6951 - dense_1_accuracy_7: 0.6521 - dense_1_accuracy_8: 0.6736 - dense_1_accuracy_9: 0.6521 - dense_1_loss: 0.0000e+00 - loss: 36.2545\n",
      "Epoch 53/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - dense_1_accuracy: 0.6736 - dense_1_accuracy_1: 0.6625 - dense_1_accuracy_10: 0.6306 - dense_1_accuracy_11: 0.6736 - dense_1_accuracy_12: 0.5549 - dense_1_accuracy_13: 0.5653 - dense_1_accuracy_14: 0.5972 - dense_1_accuracy_15: 0.5965 - dense_1_accuracy_16: 0.4993 - dense_1_accuracy_17: 0.6299 - dense_1_accuracy_18: 0.5215 - dense_1_accuracy_19: 0.5437 - dense_1_accuracy_2: 0.6625 - dense_1_accuracy_20: 0.6201 - dense_1_accuracy_21: 0.6188 - dense_1_accuracy_22: 0.5653 - dense_1_accuracy_23: 0.5097 - dense_1_accuracy_24: 0.5424 - dense_1_accuracy_25: 0.5208 - dense_1_accuracy_26: 0.4125 - dense_1_accuracy_27: 0.3153 - dense_1_accuracy_28: 0.6299 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6417 - dense_1_accuracy_4: 0.6306 - dense_1_accuracy_5: 0.6521 - dense_1_accuracy_6: 0.6521 - dense_1_accuracy_7: 0.6736 - dense_1_accuracy_8: 0.6528 - dense_1_accuracy_9: 0.6417 - dense_1_loss: 0.0000e+00 - loss: 36.1764\n",
      "Epoch 54/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - dense_1_accuracy: 0.6847 - dense_1_accuracy_1: 0.6729 - dense_1_accuracy_10: 0.6514 - dense_1_accuracy_11: 0.6632 - dense_1_accuracy_12: 0.5965 - dense_1_accuracy_13: 0.5104 - dense_1_accuracy_14: 0.6083 - dense_1_accuracy_15: 0.5764 - dense_1_accuracy_16: 0.4778 - dense_1_accuracy_17: 0.6944 - dense_1_accuracy_18: 0.5437 - dense_1_accuracy_19: 0.5972 - dense_1_accuracy_2: 0.6729 - dense_1_accuracy_20: 0.5333 - dense_1_accuracy_21: 0.5972 - dense_1_accuracy_22: 0.5104 - dense_1_accuracy_23: 0.4785 - dense_1_accuracy_24: 0.6076 - dense_1_accuracy_25: 0.4354 - dense_1_accuracy_26: 0.4562 - dense_1_accuracy_27: 0.2625 - dense_1_accuracy_28: 0.6090 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6417 - dense_1_accuracy_4: 0.6306 - dense_1_accuracy_5: 0.6625 - dense_1_accuracy_6: 0.6403 - dense_1_accuracy_7: 0.6306 - dense_1_accuracy_8: 0.6944 - dense_1_accuracy_9: 0.6625 - dense_1_loss: 0.0000e+00 - loss: 35.6758\n",
      "Epoch 55/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - dense_1_accuracy: 0.6535 - dense_1_accuracy_1: 0.6312 - dense_1_accuracy_10: 0.6083 - dense_1_accuracy_11: 0.6424 - dense_1_accuracy_12: 0.5653 - dense_1_accuracy_13: 0.5764 - dense_1_accuracy_14: 0.6090 - dense_1_accuracy_15: 0.5771 - dense_1_accuracy_16: 0.4465 - dense_1_accuracy_17: 0.5660 - dense_1_accuracy_18: 0.5431 - dense_1_accuracy_19: 0.5333 - dense_1_accuracy_2: 0.6417 - dense_1_accuracy_20: 0.5653 - dense_1_accuracy_21: 0.4361 - dense_1_accuracy_22: 0.5118 - dense_1_accuracy_23: 0.4667 - dense_1_accuracy_24: 0.5222 - dense_1_accuracy_25: 0.4458 - dense_1_accuracy_26: 0.3792 - dense_1_accuracy_27: 0.2611 - dense_1_accuracy_28: 0.7278 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6201 - dense_1_accuracy_4: 0.6306 - dense_1_accuracy_5: 0.6312 - dense_1_accuracy_6: 0.6632 - dense_1_accuracy_7: 0.6424 - dense_1_accuracy_8: 0.7056 - dense_1_accuracy_9: 0.6312 - dense_1_loss: 0.0000e+00 - loss: 35.7144\n",
      "Epoch 56/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - dense_1_accuracy: 0.6951 - dense_1_accuracy_1: 0.6410 - dense_1_accuracy_10: 0.6625 - dense_1_accuracy_11: 0.6632 - dense_1_accuracy_12: 0.5757 - dense_1_accuracy_13: 0.5757 - dense_1_accuracy_14: 0.5653 - dense_1_accuracy_15: 0.6188 - dense_1_accuracy_16: 0.5750 - dense_1_accuracy_17: 0.5868 - dense_1_accuracy_18: 0.5750 - dense_1_accuracy_19: 0.5653 - dense_1_accuracy_2: 0.6514 - dense_1_accuracy_20: 0.5222 - dense_1_accuracy_21: 0.5326 - dense_1_accuracy_22: 0.5431 - dense_1_accuracy_23: 0.3910 - dense_1_accuracy_24: 0.5764 - dense_1_accuracy_25: 0.3924 - dense_1_accuracy_26: 0.3903 - dense_1_accuracy_27: 0.3382 - dense_1_accuracy_28: 0.6840 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6417 - dense_1_accuracy_4: 0.6306 - dense_1_accuracy_5: 0.6410 - dense_1_accuracy_6: 0.6951 - dense_1_accuracy_7: 0.6618 - dense_1_accuracy_8: 0.6521 - dense_1_accuracy_9: 0.6625 - dense_1_loss: 0.0000e+00 - loss: 36.5039\n",
      "Epoch 57/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - dense_1_accuracy: 0.6951 - dense_1_accuracy_1: 0.6944 - dense_1_accuracy_10: 0.6715 - dense_1_accuracy_11: 0.6937 - dense_1_accuracy_12: 0.5750 - dense_1_accuracy_13: 0.5861 - dense_1_accuracy_14: 0.6076 - dense_1_accuracy_15: 0.6188 - dense_1_accuracy_16: 0.5312 - dense_1_accuracy_17: 0.6396 - dense_1_accuracy_18: 0.6069 - dense_1_accuracy_19: 0.5528 - dense_1_accuracy_2: 0.6826 - dense_1_accuracy_20: 0.6076 - dense_1_accuracy_21: 0.4437 - dense_1_accuracy_22: 0.5965 - dense_1_accuracy_23: 0.4764 - dense_1_accuracy_24: 0.6069 - dense_1_accuracy_25: 0.4979 - dense_1_accuracy_26: 0.4222 - dense_1_accuracy_27: 0.4326 - dense_1_accuracy_28: 0.6632 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6833 - dense_1_accuracy_4: 0.6722 - dense_1_accuracy_5: 0.6937 - dense_1_accuracy_6: 0.6729 - dense_1_accuracy_7: 0.6937 - dense_1_accuracy_8: 0.6833 - dense_1_accuracy_9: 0.6937 - dense_1_loss: 0.0000e+00 - loss: 33.7880\n",
      "Epoch 58/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - dense_1_accuracy: 0.6743 - dense_1_accuracy_1: 0.6201 - dense_1_accuracy_10: 0.5986 - dense_1_accuracy_11: 0.6417 - dense_1_accuracy_12: 0.5542 - dense_1_accuracy_13: 0.5444 - dense_1_accuracy_14: 0.6090 - dense_1_accuracy_15: 0.6299 - dense_1_accuracy_16: 0.4028 - dense_1_accuracy_17: 0.6201 - dense_1_accuracy_18: 0.5549 - dense_1_accuracy_19: 0.5333 - dense_1_accuracy_2: 0.6312 - dense_1_accuracy_20: 0.6194 - dense_1_accuracy_21: 0.4792 - dense_1_accuracy_22: 0.5542 - dense_1_accuracy_23: 0.4674 - dense_1_accuracy_24: 0.4896 - dense_1_accuracy_25: 0.4785 - dense_1_accuracy_26: 0.4028 - dense_1_accuracy_27: 0.2938 - dense_1_accuracy_28: 0.5653 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6528 - dense_1_accuracy_4: 0.6312 - dense_1_accuracy_5: 0.6417 - dense_1_accuracy_6: 0.6424 - dense_1_accuracy_7: 0.6528 - dense_1_accuracy_8: 0.6528 - dense_1_accuracy_9: 0.6521 - dense_1_loss: 0.0000e+00 - loss: 36.2291\n",
      "Epoch 59/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - dense_1_accuracy: 0.6632 - dense_1_accuracy_1: 0.6306 - dense_1_accuracy_10: 0.6090 - dense_1_accuracy_11: 0.6736 - dense_1_accuracy_12: 0.5549 - dense_1_accuracy_13: 0.5542 - dense_1_accuracy_14: 0.5875 - dense_1_accuracy_15: 0.5868 - dense_1_accuracy_16: 0.4785 - dense_1_accuracy_17: 0.6528 - dense_1_accuracy_18: 0.5444 - dense_1_accuracy_19: 0.5444 - dense_1_accuracy_2: 0.6097 - dense_1_accuracy_20: 0.5542 - dense_1_accuracy_21: 0.5764 - dense_1_accuracy_22: 0.5007 - dense_1_accuracy_23: 0.4354 - dense_1_accuracy_24: 0.4799 - dense_1_accuracy_25: 0.4576 - dense_1_accuracy_26: 0.4354 - dense_1_accuracy_27: 0.3049 - dense_1_accuracy_28: 0.6410 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6312 - dense_1_accuracy_4: 0.6521 - dense_1_accuracy_5: 0.6201 - dense_1_accuracy_6: 0.6736 - dense_1_accuracy_7: 0.6104 - dense_1_accuracy_8: 0.6201 - dense_1_accuracy_9: 0.6417 - dense_1_loss: 0.0000e+00 - loss: 36.3444\n",
      "Epoch 60/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - dense_1_accuracy: 0.6736 - dense_1_accuracy_1: 0.6410 - dense_1_accuracy_10: 0.6083 - dense_1_accuracy_11: 0.6632 - dense_1_accuracy_12: 0.5861 - dense_1_accuracy_13: 0.5861 - dense_1_accuracy_14: 0.5979 - dense_1_accuracy_15: 0.5549 - dense_1_accuracy_16: 0.4889 - dense_1_accuracy_17: 0.6847 - dense_1_accuracy_18: 0.5757 - dense_1_accuracy_19: 0.5861 - dense_1_accuracy_2: 0.6729 - dense_1_accuracy_20: 0.5646 - dense_1_accuracy_21: 0.6076 - dense_1_accuracy_22: 0.5431 - dense_1_accuracy_23: 0.4236 - dense_1_accuracy_24: 0.4778 - dense_1_accuracy_25: 0.4681 - dense_1_accuracy_26: 0.4896 - dense_1_accuracy_27: 0.3917 - dense_1_accuracy_28: 0.7181 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6625 - dense_1_accuracy_4: 0.6292 - dense_1_accuracy_5: 0.6417 - dense_1_accuracy_6: 0.6410 - dense_1_accuracy_7: 0.6410 - dense_1_accuracy_8: 0.6410 - dense_1_accuracy_9: 0.6521 - dense_1_loss: 0.0000e+00 - loss: 34.9383\n",
      "Epoch 61/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - dense_1_accuracy: 0.6639 - dense_1_accuracy_1: 0.6521 - dense_1_accuracy_10: 0.6194 - dense_1_accuracy_11: 0.6528 - dense_1_accuracy_12: 0.5437 - dense_1_accuracy_13: 0.5333 - dense_1_accuracy_14: 0.5667 - dense_1_accuracy_15: 0.5771 - dense_1_accuracy_16: 0.5111 - dense_1_accuracy_17: 0.6090 - dense_1_accuracy_18: 0.5542 - dense_1_accuracy_19: 0.5979 - dense_1_accuracy_2: 0.6625 - dense_1_accuracy_20: 0.5646 - dense_1_accuracy_21: 0.5444 - dense_1_accuracy_22: 0.5646 - dense_1_accuracy_23: 0.3924 - dense_1_accuracy_24: 0.5646 - dense_1_accuracy_25: 0.4882 - dense_1_accuracy_26: 0.4660 - dense_1_accuracy_27: 0.3479 - dense_1_accuracy_28: 0.6937 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6410 - dense_1_accuracy_4: 0.5875 - dense_1_accuracy_5: 0.6306 - dense_1_accuracy_6: 0.6521 - dense_1_accuracy_7: 0.6632 - dense_1_accuracy_8: 0.6528 - dense_1_accuracy_9: 0.6521 - dense_1_loss: 0.0000e+00 - loss: 35.3380\n",
      "Epoch 62/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - dense_1_accuracy: 0.6632 - dense_1_accuracy_1: 0.6521 - dense_1_accuracy_10: 0.6410 - dense_1_accuracy_11: 0.6736 - dense_1_accuracy_12: 0.5444 - dense_1_accuracy_13: 0.6076 - dense_1_accuracy_14: 0.6083 - dense_1_accuracy_15: 0.5875 - dense_1_accuracy_16: 0.5000 - dense_1_accuracy_17: 0.6194 - dense_1_accuracy_18: 0.5979 - dense_1_accuracy_19: 0.6194 - dense_1_accuracy_2: 0.6417 - dense_1_accuracy_20: 0.6076 - dense_1_accuracy_21: 0.5104 - dense_1_accuracy_22: 0.5333 - dense_1_accuracy_23: 0.4681 - dense_1_accuracy_24: 0.5444 - dense_1_accuracy_25: 0.5319 - dense_1_accuracy_26: 0.4139 - dense_1_accuracy_27: 0.3576 - dense_1_accuracy_28: 0.7625 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6521 - dense_1_accuracy_4: 0.6306 - dense_1_accuracy_5: 0.6417 - dense_1_accuracy_6: 0.6632 - dense_1_accuracy_7: 0.6528 - dense_1_accuracy_8: 0.6417 - dense_1_accuracy_9: 0.6521 - dense_1_loss: 0.0000e+00 - loss: 34.9037\n",
      "Epoch 63/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - dense_1_accuracy: 0.6951 - dense_1_accuracy_1: 0.6521 - dense_1_accuracy_10: 0.5979 - dense_1_accuracy_11: 0.7056 - dense_1_accuracy_12: 0.5757 - dense_1_accuracy_13: 0.5972 - dense_1_accuracy_14: 0.6194 - dense_1_accuracy_15: 0.6083 - dense_1_accuracy_16: 0.5319 - dense_1_accuracy_17: 0.6083 - dense_1_accuracy_18: 0.5757 - dense_1_accuracy_19: 0.5979 - dense_1_accuracy_2: 0.6729 - dense_1_accuracy_20: 0.5972 - dense_1_accuracy_21: 0.5972 - dense_1_accuracy_22: 0.5431 - dense_1_accuracy_23: 0.5431 - dense_1_accuracy_24: 0.6514 - dense_1_accuracy_25: 0.5437 - dense_1_accuracy_26: 0.4458 - dense_1_accuracy_27: 0.4014 - dense_1_accuracy_28: 0.7063 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6410 - dense_1_accuracy_4: 0.6625 - dense_1_accuracy_5: 0.6729 - dense_1_accuracy_6: 0.6632 - dense_1_accuracy_7: 0.6736 - dense_1_accuracy_8: 0.6729 - dense_1_accuracy_9: 0.6625 - dense_1_loss: 0.0000e+00 - loss: 34.2657\n",
      "Epoch 64/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - dense_1_accuracy: 0.6535 - dense_1_accuracy_1: 0.6417 - dense_1_accuracy_10: 0.6410 - dense_1_accuracy_11: 0.6632 - dense_1_accuracy_12: 0.5444 - dense_1_accuracy_13: 0.5222 - dense_1_accuracy_14: 0.6194 - dense_1_accuracy_15: 0.5979 - dense_1_accuracy_16: 0.5319 - dense_1_accuracy_17: 0.6208 - dense_1_accuracy_18: 0.5653 - dense_1_accuracy_19: 0.5868 - dense_1_accuracy_2: 0.6306 - dense_1_accuracy_20: 0.5646 - dense_1_accuracy_21: 0.6292 - dense_1_accuracy_22: 0.5222 - dense_1_accuracy_23: 0.5549 - dense_1_accuracy_24: 0.6194 - dense_1_accuracy_25: 0.5229 - dense_1_accuracy_26: 0.5000 - dense_1_accuracy_27: 0.3250 - dense_1_accuracy_28: 0.5979 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6417 - dense_1_accuracy_4: 0.6417 - dense_1_accuracy_5: 0.6521 - dense_1_accuracy_6: 0.6528 - dense_1_accuracy_7: 0.6521 - dense_1_accuracy_8: 0.6424 - dense_1_accuracy_9: 0.6417 - dense_1_loss: 0.0000e+00 - loss: 34.4383\n",
      "Epoch 65/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - dense_1_accuracy: 0.6847 - dense_1_accuracy_1: 0.6625 - dense_1_accuracy_10: 0.5986 - dense_1_accuracy_11: 0.6632 - dense_1_accuracy_12: 0.5764 - dense_1_accuracy_13: 0.5340 - dense_1_accuracy_14: 0.5986 - dense_1_accuracy_15: 0.5771 - dense_1_accuracy_16: 0.5333 - dense_1_accuracy_17: 0.6208 - dense_1_accuracy_18: 0.5229 - dense_1_accuracy_19: 0.5444 - dense_1_accuracy_2: 0.6306 - dense_1_accuracy_20: 0.5764 - dense_1_accuracy_21: 0.5875 - dense_1_accuracy_22: 0.5437 - dense_1_accuracy_23: 0.5007 - dense_1_accuracy_24: 0.5444 - dense_1_accuracy_25: 0.5229 - dense_1_accuracy_26: 0.4681 - dense_1_accuracy_27: 0.3708 - dense_1_accuracy_28: 0.6625 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6417 - dense_1_accuracy_4: 0.6097 - dense_1_accuracy_5: 0.6417 - dense_1_accuracy_6: 0.6417 - dense_1_accuracy_7: 0.6528 - dense_1_accuracy_8: 0.6951 - dense_1_accuracy_9: 0.6306 - dense_1_loss: 0.0000e+00 - loss: 35.7348\n",
      "Epoch 66/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - dense_1_accuracy: 0.6743 - dense_1_accuracy_1: 0.6306 - dense_1_accuracy_10: 0.6306 - dense_1_accuracy_11: 0.6528 - dense_1_accuracy_12: 0.5542 - dense_1_accuracy_13: 0.5646 - dense_1_accuracy_14: 0.6306 - dense_1_accuracy_15: 0.5875 - dense_1_accuracy_16: 0.4681 - dense_1_accuracy_17: 0.6201 - dense_1_accuracy_18: 0.5660 - dense_1_accuracy_19: 0.5972 - dense_1_accuracy_2: 0.6306 - dense_1_accuracy_20: 0.5875 - dense_1_accuracy_21: 0.6083 - dense_1_accuracy_22: 0.5757 - dense_1_accuracy_23: 0.4472 - dense_1_accuracy_24: 0.5542 - dense_1_accuracy_25: 0.5229 - dense_1_accuracy_26: 0.4889 - dense_1_accuracy_27: 0.3160 - dense_1_accuracy_28: 0.6826 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6625 - dense_1_accuracy_4: 0.6521 - dense_1_accuracy_5: 0.5986 - dense_1_accuracy_6: 0.6417 - dense_1_accuracy_7: 0.6521 - dense_1_accuracy_8: 0.6736 - dense_1_accuracy_9: 0.6521 - dense_1_loss: 0.0000e+00 - loss: 35.6505\n",
      "Epoch 67/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - dense_1_accuracy: 0.6743 - dense_1_accuracy_1: 0.6201 - dense_1_accuracy_10: 0.6097 - dense_1_accuracy_11: 0.6424 - dense_1_accuracy_12: 0.5444 - dense_1_accuracy_13: 0.5444 - dense_1_accuracy_14: 0.6194 - dense_1_accuracy_15: 0.6083 - dense_1_accuracy_16: 0.4896 - dense_1_accuracy_17: 0.6201 - dense_1_accuracy_18: 0.6090 - dense_1_accuracy_19: 0.5660 - dense_1_accuracy_2: 0.6312 - dense_1_accuracy_20: 0.6083 - dense_1_accuracy_21: 0.5444 - dense_1_accuracy_22: 0.5340 - dense_1_accuracy_23: 0.5215 - dense_1_accuracy_24: 0.5868 - dense_1_accuracy_25: 0.5326 - dense_1_accuracy_26: 0.4576 - dense_1_accuracy_27: 0.3694 - dense_1_accuracy_28: 0.7174 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6097 - dense_1_accuracy_4: 0.6090 - dense_1_accuracy_5: 0.6417 - dense_1_accuracy_6: 0.6743 - dense_1_accuracy_7: 0.6319 - dense_1_accuracy_8: 0.6632 - dense_1_accuracy_9: 0.6312 - dense_1_loss: 0.0000e+00 - loss: 35.0430\n",
      "Epoch 68/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - dense_1_accuracy: 0.6951 - dense_1_accuracy_1: 0.6625 - dense_1_accuracy_10: 0.6083 - dense_1_accuracy_11: 0.7153 - dense_1_accuracy_12: 0.5750 - dense_1_accuracy_13: 0.5528 - dense_1_accuracy_14: 0.6181 - dense_1_accuracy_15: 0.6722 - dense_1_accuracy_16: 0.5104 - dense_1_accuracy_17: 0.6424 - dense_1_accuracy_18: 0.5965 - dense_1_accuracy_19: 0.5868 - dense_1_accuracy_2: 0.6840 - dense_1_accuracy_20: 0.6618 - dense_1_accuracy_21: 0.5861 - dense_1_accuracy_22: 0.6083 - dense_1_accuracy_23: 0.5542 - dense_1_accuracy_24: 0.6403 - dense_1_accuracy_25: 0.5306 - dense_1_accuracy_26: 0.4993 - dense_1_accuracy_27: 0.3465 - dense_1_accuracy_28: 0.6410 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6514 - dense_1_accuracy_4: 0.6299 - dense_1_accuracy_5: 0.6937 - dense_1_accuracy_6: 0.6625 - dense_1_accuracy_7: 0.6944 - dense_1_accuracy_8: 0.6632 - dense_1_accuracy_9: 0.7049 - dense_1_loss: 0.0000e+00 - loss: 33.9185\n",
      "Epoch 69/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - dense_1_accuracy: 0.6639 - dense_1_accuracy_1: 0.6312 - dense_1_accuracy_10: 0.6306 - dense_1_accuracy_11: 0.6528 - dense_1_accuracy_12: 0.5653 - dense_1_accuracy_13: 0.5549 - dense_1_accuracy_14: 0.6188 - dense_1_accuracy_15: 0.5764 - dense_1_accuracy_16: 0.5653 - dense_1_accuracy_17: 0.6528 - dense_1_accuracy_18: 0.5868 - dense_1_accuracy_19: 0.5437 - dense_1_accuracy_2: 0.6521 - dense_1_accuracy_20: 0.6090 - dense_1_accuracy_21: 0.6194 - dense_1_accuracy_22: 0.5444 - dense_1_accuracy_23: 0.5118 - dense_1_accuracy_24: 0.5556 - dense_1_accuracy_25: 0.5111 - dense_1_accuracy_26: 0.4465 - dense_1_accuracy_27: 0.2507 - dense_1_accuracy_28: 0.6937 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6424 - dense_1_accuracy_4: 0.6417 - dense_1_accuracy_5: 0.6417 - dense_1_accuracy_6: 0.6528 - dense_1_accuracy_7: 0.6521 - dense_1_accuracy_8: 0.6743 - dense_1_accuracy_9: 0.6312 - dense_1_loss: 0.0000e+00 - loss: 35.8467\n",
      "Epoch 70/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - dense_1_accuracy: 0.6951 - dense_1_accuracy_1: 0.6625 - dense_1_accuracy_10: 0.6306 - dense_1_accuracy_11: 0.6736 - dense_1_accuracy_12: 0.5757 - dense_1_accuracy_13: 0.5549 - dense_1_accuracy_14: 0.5771 - dense_1_accuracy_15: 0.6188 - dense_1_accuracy_16: 0.5222 - dense_1_accuracy_17: 0.6299 - dense_1_accuracy_18: 0.5125 - dense_1_accuracy_19: 0.4792 - dense_1_accuracy_2: 0.6410 - dense_1_accuracy_20: 0.5764 - dense_1_accuracy_21: 0.6090 - dense_1_accuracy_22: 0.5653 - dense_1_accuracy_23: 0.5111 - dense_1_accuracy_24: 0.6083 - dense_1_accuracy_25: 0.5000 - dense_1_accuracy_26: 0.3701 - dense_1_accuracy_27: 0.2958 - dense_1_accuracy_28: 0.6194 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6299 - dense_1_accuracy_4: 0.6736 - dense_1_accuracy_5: 0.6306 - dense_1_accuracy_6: 0.6840 - dense_1_accuracy_7: 0.6410 - dense_1_accuracy_8: 0.6840 - dense_1_accuracy_9: 0.6410 - dense_1_loss: 0.0000e+00 - loss: 35.5826\n",
      "Epoch 71/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - dense_1_accuracy: 0.6632 - dense_1_accuracy_1: 0.6944 - dense_1_accuracy_10: 0.6514 - dense_1_accuracy_11: 0.6528 - dense_1_accuracy_12: 0.5861 - dense_1_accuracy_13: 0.5861 - dense_1_accuracy_14: 0.6299 - dense_1_accuracy_15: 0.6299 - dense_1_accuracy_16: 0.4681 - dense_1_accuracy_17: 0.6840 - dense_1_accuracy_18: 0.5965 - dense_1_accuracy_19: 0.5861 - dense_1_accuracy_2: 0.6514 - dense_1_accuracy_20: 0.6299 - dense_1_accuracy_21: 0.6188 - dense_1_accuracy_22: 0.5868 - dense_1_accuracy_23: 0.4667 - dense_1_accuracy_24: 0.5639 - dense_1_accuracy_25: 0.4451 - dense_1_accuracy_26: 0.4451 - dense_1_accuracy_27: 0.3042 - dense_1_accuracy_28: 0.5757 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6729 - dense_1_accuracy_4: 0.6833 - dense_1_accuracy_5: 0.6625 - dense_1_accuracy_6: 0.6625 - dense_1_accuracy_7: 0.6944 - dense_1_accuracy_8: 0.6840 - dense_1_accuracy_9: 0.6521 - dense_1_loss: 0.0000e+00 - loss: 35.2155 \n",
      "Epoch 72/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - dense_1_accuracy: 0.6743 - dense_1_accuracy_1: 0.6521 - dense_1_accuracy_10: 0.6514 - dense_1_accuracy_11: 0.6639 - dense_1_accuracy_12: 0.5764 - dense_1_accuracy_13: 0.5861 - dense_1_accuracy_14: 0.5882 - dense_1_accuracy_15: 0.6090 - dense_1_accuracy_16: 0.4903 - dense_1_accuracy_17: 0.7056 - dense_1_accuracy_18: 0.5653 - dense_1_accuracy_19: 0.5972 - dense_1_accuracy_2: 0.6410 - dense_1_accuracy_20: 0.5764 - dense_1_accuracy_21: 0.5542 - dense_1_accuracy_22: 0.5868 - dense_1_accuracy_23: 0.4792 - dense_1_accuracy_24: 0.5326 - dense_1_accuracy_25: 0.4785 - dense_1_accuracy_26: 0.4125 - dense_1_accuracy_27: 0.2944 - dense_1_accuracy_28: 0.7167 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6625 - dense_1_accuracy_4: 0.6625 - dense_1_accuracy_5: 0.6417 - dense_1_accuracy_6: 0.6736 - dense_1_accuracy_7: 0.6521 - dense_1_accuracy_8: 0.6736 - dense_1_accuracy_9: 0.6306 - dense_1_loss: 0.0000e+00 - loss: 35.4542\n",
      "Epoch 73/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - dense_1_accuracy: 0.6736 - dense_1_accuracy_1: 0.6194 - dense_1_accuracy_10: 0.6306 - dense_1_accuracy_11: 0.6736 - dense_1_accuracy_12: 0.5757 - dense_1_accuracy_13: 0.5542 - dense_1_accuracy_14: 0.6611 - dense_1_accuracy_15: 0.6403 - dense_1_accuracy_16: 0.4778 - dense_1_accuracy_17: 0.6528 - dense_1_accuracy_18: 0.5646 - dense_1_accuracy_19: 0.5757 - dense_1_accuracy_2: 0.6194 - dense_1_accuracy_20: 0.5861 - dense_1_accuracy_21: 0.5868 - dense_1_accuracy_22: 0.5215 - dense_1_accuracy_23: 0.5535 - dense_1_accuracy_24: 0.6188 - dense_1_accuracy_25: 0.4243 - dense_1_accuracy_26: 0.4132 - dense_1_accuracy_27: 0.2500 - dense_1_accuracy_28: 0.5556 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6306 - dense_1_accuracy_4: 0.5868 - dense_1_accuracy_5: 0.6625 - dense_1_accuracy_6: 0.6528 - dense_1_accuracy_7: 0.6736 - dense_1_accuracy_8: 0.6632 - dense_1_accuracy_9: 0.6521 - dense_1_loss: 0.0000e+00 - loss: 34.9085\n",
      "Epoch 74/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - dense_1_accuracy: 0.6424 - dense_1_accuracy_1: 0.5889 - dense_1_accuracy_10: 0.6104 - dense_1_accuracy_11: 0.6208 - dense_1_accuracy_12: 0.5556 - dense_1_accuracy_13: 0.5340 - dense_1_accuracy_14: 0.5556 - dense_1_accuracy_15: 0.5875 - dense_1_accuracy_16: 0.4799 - dense_1_accuracy_17: 0.6104 - dense_1_accuracy_18: 0.5236 - dense_1_accuracy_19: 0.5028 - dense_1_accuracy_2: 0.5778 - dense_1_accuracy_20: 0.5340 - dense_1_accuracy_21: 0.5771 - dense_1_accuracy_22: 0.4806 - dense_1_accuracy_23: 0.4903 - dense_1_accuracy_24: 0.5444 - dense_1_accuracy_25: 0.4806 - dense_1_accuracy_26: 0.4354 - dense_1_accuracy_27: 0.2840 - dense_1_accuracy_28: 0.6632 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.5889 - dense_1_accuracy_4: 0.5882 - dense_1_accuracy_5: 0.5993 - dense_1_accuracy_6: 0.6431 - dense_1_accuracy_7: 0.5993 - dense_1_accuracy_8: 0.6535 - dense_1_accuracy_9: 0.6104 - dense_1_loss: 0.0000e+00 - loss: 36.9869\n",
      "Epoch 75/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - dense_1_accuracy: 0.6743 - dense_1_accuracy_1: 0.6417 - dense_1_accuracy_10: 0.5986 - dense_1_accuracy_11: 0.6528 - dense_1_accuracy_12: 0.5444 - dense_1_accuracy_13: 0.5229 - dense_1_accuracy_14: 0.5667 - dense_1_accuracy_15: 0.5979 - dense_1_accuracy_16: 0.4792 - dense_1_accuracy_17: 0.6632 - dense_1_accuracy_18: 0.5549 - dense_1_accuracy_19: 0.5979 - dense_1_accuracy_2: 0.6417 - dense_1_accuracy_20: 0.5757 - dense_1_accuracy_21: 0.6097 - dense_1_accuracy_22: 0.5236 - dense_1_accuracy_23: 0.4896 - dense_1_accuracy_24: 0.5229 - dense_1_accuracy_25: 0.4792 - dense_1_accuracy_26: 0.4785 - dense_1_accuracy_27: 0.3167 - dense_1_accuracy_28: 0.6937 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6417 - dense_1_accuracy_4: 0.6097 - dense_1_accuracy_5: 0.6417 - dense_1_accuracy_6: 0.6632 - dense_1_accuracy_7: 0.6528 - dense_1_accuracy_8: 0.6639 - dense_1_accuracy_9: 0.6417 - dense_1_loss: 0.0000e+00 - loss: 35.1227\n",
      "Epoch 76/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - dense_1_accuracy: 0.7056 - dense_1_accuracy_1: 0.6729 - dense_1_accuracy_10: 0.6611 - dense_1_accuracy_11: 0.6729 - dense_1_accuracy_12: 0.6181 - dense_1_accuracy_13: 0.5958 - dense_1_accuracy_14: 0.6396 - dense_1_accuracy_15: 0.6403 - dense_1_accuracy_16: 0.5208 - dense_1_accuracy_17: 0.6937 - dense_1_accuracy_18: 0.5542 - dense_1_accuracy_19: 0.5535 - dense_1_accuracy_2: 0.6625 - dense_1_accuracy_20: 0.5861 - dense_1_accuracy_21: 0.6500 - dense_1_accuracy_22: 0.5750 - dense_1_accuracy_23: 0.4674 - dense_1_accuracy_24: 0.5972 - dense_1_accuracy_25: 0.4785 - dense_1_accuracy_26: 0.4347 - dense_1_accuracy_27: 0.2931 - dense_1_accuracy_28: 0.6750 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6729 - dense_1_accuracy_4: 0.6396 - dense_1_accuracy_5: 0.7153 - dense_1_accuracy_6: 0.6618 - dense_1_accuracy_7: 0.7049 - dense_1_accuracy_8: 0.6847 - dense_1_accuracy_9: 0.6618 - dense_1_loss: 0.0000e+00 - loss: 33.8653\n",
      "Epoch 77/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - dense_1_accuracy: 0.6743 - dense_1_accuracy_1: 0.6417 - dense_1_accuracy_10: 0.6090 - dense_1_accuracy_11: 0.6528 - dense_1_accuracy_12: 0.5868 - dense_1_accuracy_13: 0.5757 - dense_1_accuracy_14: 0.6194 - dense_1_accuracy_15: 0.5986 - dense_1_accuracy_16: 0.5542 - dense_1_accuracy_17: 0.6424 - dense_1_accuracy_18: 0.6194 - dense_1_accuracy_19: 0.5979 - dense_1_accuracy_2: 0.6306 - dense_1_accuracy_20: 0.6201 - dense_1_accuracy_21: 0.5222 - dense_1_accuracy_22: 0.5549 - dense_1_accuracy_23: 0.5007 - dense_1_accuracy_24: 0.5437 - dense_1_accuracy_25: 0.4562 - dense_1_accuracy_26: 0.4354 - dense_1_accuracy_27: 0.3590 - dense_1_accuracy_28: 0.7389 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6201 - dense_1_accuracy_4: 0.6194 - dense_1_accuracy_5: 0.6312 - dense_1_accuracy_6: 0.6632 - dense_1_accuracy_7: 0.6424 - dense_1_accuracy_8: 0.6736 - dense_1_accuracy_9: 0.6312 - dense_1_loss: 0.0000e+00 - loss: 34.7534\n",
      "Epoch 78/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - dense_1_accuracy: 0.6639 - dense_1_accuracy_1: 0.6521 - dense_1_accuracy_10: 0.6410 - dense_1_accuracy_11: 0.6632 - dense_1_accuracy_12: 0.5653 - dense_1_accuracy_13: 0.5118 - dense_1_accuracy_14: 0.6188 - dense_1_accuracy_15: 0.6083 - dense_1_accuracy_16: 0.4896 - dense_1_accuracy_17: 0.6312 - dense_1_accuracy_18: 0.5319 - dense_1_accuracy_19: 0.5542 - dense_1_accuracy_2: 0.6306 - dense_1_accuracy_20: 0.5340 - dense_1_accuracy_21: 0.5854 - dense_1_accuracy_22: 0.5000 - dense_1_accuracy_23: 0.4674 - dense_1_accuracy_24: 0.5646 - dense_1_accuracy_25: 0.5542 - dense_1_accuracy_26: 0.5208 - dense_1_accuracy_27: 0.3049 - dense_1_accuracy_28: 0.5299 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6306 - dense_1_accuracy_4: 0.6312 - dense_1_accuracy_5: 0.6625 - dense_1_accuracy_6: 0.6417 - dense_1_accuracy_7: 0.6625 - dense_1_accuracy_8: 0.6632 - dense_1_accuracy_9: 0.6410 - dense_1_loss: 0.0000e+00 - loss: 35.9565\n",
      "Epoch 79/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - dense_1_accuracy: 0.6847 - dense_1_accuracy_1: 0.6625 - dense_1_accuracy_10: 0.6403 - dense_1_accuracy_11: 0.6833 - dense_1_accuracy_12: 0.5965 - dense_1_accuracy_13: 0.5326 - dense_1_accuracy_14: 0.5861 - dense_1_accuracy_15: 0.5972 - dense_1_accuracy_16: 0.5424 - dense_1_accuracy_17: 0.6521 - dense_1_accuracy_18: 0.6083 - dense_1_accuracy_19: 0.5535 - dense_1_accuracy_2: 0.6937 - dense_1_accuracy_20: 0.5535 - dense_1_accuracy_21: 0.6181 - dense_1_accuracy_22: 0.5535 - dense_1_accuracy_23: 0.4896 - dense_1_accuracy_24: 0.6507 - dense_1_accuracy_25: 0.5437 - dense_1_accuracy_26: 0.4889 - dense_1_accuracy_27: 0.4118 - dense_1_accuracy_28: 0.7188 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6729 - dense_1_accuracy_4: 0.6521 - dense_1_accuracy_5: 0.6625 - dense_1_accuracy_6: 0.6618 - dense_1_accuracy_7: 0.6951 - dense_1_accuracy_8: 0.6944 - dense_1_accuracy_9: 0.6514 - dense_1_loss: 0.0000e+00 - loss: 33.2837\n",
      "Epoch 80/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - dense_1_accuracy: 0.6639 - dense_1_accuracy_1: 0.6201 - dense_1_accuracy_10: 0.5986 - dense_1_accuracy_11: 0.6632 - dense_1_accuracy_12: 0.5340 - dense_1_accuracy_13: 0.5771 - dense_1_accuracy_14: 0.6097 - dense_1_accuracy_15: 0.6194 - dense_1_accuracy_16: 0.4903 - dense_1_accuracy_17: 0.6639 - dense_1_accuracy_18: 0.5549 - dense_1_accuracy_19: 0.5660 - dense_1_accuracy_2: 0.6201 - dense_1_accuracy_20: 0.5875 - dense_1_accuracy_21: 0.5333 - dense_1_accuracy_22: 0.5229 - dense_1_accuracy_23: 0.5007 - dense_1_accuracy_24: 0.5014 - dense_1_accuracy_25: 0.5215 - dense_1_accuracy_26: 0.4465 - dense_1_accuracy_27: 0.3042 - dense_1_accuracy_28: 0.6736 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6312 - dense_1_accuracy_4: 0.6097 - dense_1_accuracy_5: 0.6417 - dense_1_accuracy_6: 0.6312 - dense_1_accuracy_7: 0.6632 - dense_1_accuracy_8: 0.6639 - dense_1_accuracy_9: 0.6097 - dense_1_loss: 0.0000e+00 - loss: 35.7684\n",
      "Epoch 81/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - dense_1_accuracy: 0.6743 - dense_1_accuracy_1: 0.6625 - dense_1_accuracy_10: 0.5972 - dense_1_accuracy_11: 0.6639 - dense_1_accuracy_12: 0.5229 - dense_1_accuracy_13: 0.5757 - dense_1_accuracy_14: 0.5875 - dense_1_accuracy_15: 0.5875 - dense_1_accuracy_16: 0.5312 - dense_1_accuracy_17: 0.5868 - dense_1_accuracy_18: 0.6076 - dense_1_accuracy_19: 0.5556 - dense_1_accuracy_2: 0.6521 - dense_1_accuracy_20: 0.5868 - dense_1_accuracy_21: 0.5431 - dense_1_accuracy_22: 0.5535 - dense_1_accuracy_23: 0.4667 - dense_1_accuracy_24: 0.6306 - dense_1_accuracy_25: 0.4451 - dense_1_accuracy_26: 0.4236 - dense_1_accuracy_27: 0.3576 - dense_1_accuracy_28: 0.7611 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6410 - dense_1_accuracy_4: 0.6181 - dense_1_accuracy_5: 0.6521 - dense_1_accuracy_6: 0.6090 - dense_1_accuracy_7: 0.6944 - dense_1_accuracy_8: 0.6951 - dense_1_accuracy_9: 0.6312 - dense_1_loss: 0.0000e+00 - loss: 35.4903\n",
      "Epoch 82/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - dense_1_accuracy: 0.6847 - dense_1_accuracy_1: 0.5986 - dense_1_accuracy_10: 0.5993 - dense_1_accuracy_11: 0.6736 - dense_1_accuracy_12: 0.5556 - dense_1_accuracy_13: 0.5014 - dense_1_accuracy_14: 0.5771 - dense_1_accuracy_15: 0.6306 - dense_1_accuracy_16: 0.4681 - dense_1_accuracy_17: 0.5993 - dense_1_accuracy_18: 0.5229 - dense_1_accuracy_19: 0.4806 - dense_1_accuracy_2: 0.6312 - dense_1_accuracy_20: 0.5875 - dense_1_accuracy_21: 0.4910 - dense_1_accuracy_22: 0.5007 - dense_1_accuracy_23: 0.3931 - dense_1_accuracy_24: 0.4903 - dense_1_accuracy_25: 0.3819 - dense_1_accuracy_26: 0.3826 - dense_1_accuracy_27: 0.2944 - dense_1_accuracy_28: 0.6632 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6201 - dense_1_accuracy_4: 0.6201 - dense_1_accuracy_5: 0.6632 - dense_1_accuracy_6: 0.6312 - dense_1_accuracy_7: 0.6528 - dense_1_accuracy_8: 0.6632 - dense_1_accuracy_9: 0.6632 - dense_1_loss: 0.0000e+00 - loss: 35.6254\n",
      "Epoch 83/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - dense_1_accuracy: 0.6743 - dense_1_accuracy_1: 0.6417 - dense_1_accuracy_10: 0.5771 - dense_1_accuracy_11: 0.6632 - dense_1_accuracy_12: 0.5229 - dense_1_accuracy_13: 0.5111 - dense_1_accuracy_14: 0.6201 - dense_1_accuracy_15: 0.5875 - dense_1_accuracy_16: 0.4681 - dense_1_accuracy_17: 0.5771 - dense_1_accuracy_18: 0.5007 - dense_1_accuracy_19: 0.5007 - dense_1_accuracy_2: 0.6521 - dense_1_accuracy_20: 0.5118 - dense_1_accuracy_21: 0.5431 - dense_1_accuracy_22: 0.4889 - dense_1_accuracy_23: 0.4576 - dense_1_accuracy_24: 0.4889 - dense_1_accuracy_25: 0.4340 - dense_1_accuracy_26: 0.4778 - dense_1_accuracy_27: 0.3146 - dense_1_accuracy_28: 0.5861 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6312 - dense_1_accuracy_4: 0.6410 - dense_1_accuracy_5: 0.6417 - dense_1_accuracy_6: 0.6201 - dense_1_accuracy_7: 0.6306 - dense_1_accuracy_8: 0.6632 - dense_1_accuracy_9: 0.6312 - dense_1_loss: 0.0000e+00 - loss: 36.6714\n",
      "Epoch 84/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - dense_1_accuracy: 0.6639 - dense_1_accuracy_1: 0.6312 - dense_1_accuracy_10: 0.6306 - dense_1_accuracy_11: 0.6424 - dense_1_accuracy_12: 0.5549 - dense_1_accuracy_13: 0.5437 - dense_1_accuracy_14: 0.5764 - dense_1_accuracy_15: 0.5556 - dense_1_accuracy_16: 0.5000 - dense_1_accuracy_17: 0.6076 - dense_1_accuracy_18: 0.5333 - dense_1_accuracy_19: 0.5646 - dense_1_accuracy_2: 0.6528 - dense_1_accuracy_20: 0.5868 - dense_1_accuracy_21: 0.5771 - dense_1_accuracy_22: 0.5542 - dense_1_accuracy_23: 0.4569 - dense_1_accuracy_24: 0.5215 - dense_1_accuracy_25: 0.4889 - dense_1_accuracy_26: 0.3806 - dense_1_accuracy_27: 0.2944 - dense_1_accuracy_28: 0.6312 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6312 - dense_1_accuracy_4: 0.6201 - dense_1_accuracy_5: 0.6097 - dense_1_accuracy_6: 0.6306 - dense_1_accuracy_7: 0.6528 - dense_1_accuracy_8: 0.6743 - dense_1_accuracy_9: 0.6312 - dense_1_loss: 0.0000e+00 - loss: 35.0934\n",
      "Epoch 85/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - dense_1_accuracy: 0.6431 - dense_1_accuracy_1: 0.6000 - dense_1_accuracy_10: 0.5889 - dense_1_accuracy_11: 0.6215 - dense_1_accuracy_12: 0.5021 - dense_1_accuracy_13: 0.5028 - dense_1_accuracy_14: 0.5451 - dense_1_accuracy_15: 0.5451 - dense_1_accuracy_16: 0.4590 - dense_1_accuracy_17: 0.5118 - dense_1_accuracy_18: 0.4799 - dense_1_accuracy_19: 0.4806 - dense_1_accuracy_2: 0.6104 - dense_1_accuracy_20: 0.5556 - dense_1_accuracy_21: 0.5021 - dense_1_accuracy_22: 0.4799 - dense_1_accuracy_23: 0.4028 - dense_1_accuracy_24: 0.5556 - dense_1_accuracy_25: 0.4792 - dense_1_accuracy_26: 0.4243 - dense_1_accuracy_27: 0.3375 - dense_1_accuracy_28: 0.6729 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6000 - dense_1_accuracy_4: 0.6000 - dense_1_accuracy_5: 0.6000 - dense_1_accuracy_6: 0.6319 - dense_1_accuracy_7: 0.6104 - dense_1_accuracy_8: 0.6319 - dense_1_accuracy_9: 0.6215 - dense_1_loss: 0.0000e+00 - loss: 37.3915\n",
      "Epoch 86/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - dense_1_accuracy: 0.7056 - dense_1_accuracy_1: 0.6729 - dense_1_accuracy_10: 0.6507 - dense_1_accuracy_11: 0.6944 - dense_1_accuracy_12: 0.5972 - dense_1_accuracy_13: 0.5750 - dense_1_accuracy_14: 0.5972 - dense_1_accuracy_15: 0.6292 - dense_1_accuracy_16: 0.5521 - dense_1_accuracy_17: 0.5653 - dense_1_accuracy_18: 0.6069 - dense_1_accuracy_19: 0.6188 - dense_1_accuracy_2: 0.6410 - dense_1_accuracy_20: 0.5972 - dense_1_accuracy_21: 0.5424 - dense_1_accuracy_22: 0.4993 - dense_1_accuracy_23: 0.5097 - dense_1_accuracy_24: 0.6299 - dense_1_accuracy_25: 0.4458 - dense_1_accuracy_26: 0.5000 - dense_1_accuracy_27: 0.3590 - dense_1_accuracy_28: 0.6639 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6729 - dense_1_accuracy_4: 0.6729 - dense_1_accuracy_5: 0.6625 - dense_1_accuracy_6: 0.6840 - dense_1_accuracy_7: 0.6625 - dense_1_accuracy_8: 0.7049 - dense_1_accuracy_9: 0.6625 - dense_1_loss: 0.0000e+00 - loss: 33.8587\n",
      "Epoch 87/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - dense_1_accuracy: 0.6639 - dense_1_accuracy_1: 0.6312 - dense_1_accuracy_10: 0.5986 - dense_1_accuracy_11: 0.6736 - dense_1_accuracy_12: 0.5549 - dense_1_accuracy_13: 0.5542 - dense_1_accuracy_14: 0.5764 - dense_1_accuracy_15: 0.6188 - dense_1_accuracy_16: 0.4465 - dense_1_accuracy_17: 0.6104 - dense_1_accuracy_18: 0.5333 - dense_1_accuracy_19: 0.5340 - dense_1_accuracy_2: 0.6306 - dense_1_accuracy_20: 0.5229 - dense_1_accuracy_21: 0.4153 - dense_1_accuracy_22: 0.4354 - dense_1_accuracy_23: 0.3826 - dense_1_accuracy_24: 0.5014 - dense_1_accuracy_25: 0.3917 - dense_1_accuracy_26: 0.4250 - dense_1_accuracy_27: 0.2931 - dense_1_accuracy_28: 0.6743 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6528 - dense_1_accuracy_4: 0.6201 - dense_1_accuracy_5: 0.6521 - dense_1_accuracy_6: 0.6312 - dense_1_accuracy_7: 0.6632 - dense_1_accuracy_8: 0.6639 - dense_1_accuracy_9: 0.6521 - dense_1_loss: 0.0000e+00 - loss: 35.7708\n",
      "Epoch 88/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - dense_1_accuracy: 0.6847 - dense_1_accuracy_1: 0.6410 - dense_1_accuracy_10: 0.5875 - dense_1_accuracy_11: 0.6736 - dense_1_accuracy_12: 0.5868 - dense_1_accuracy_13: 0.5437 - dense_1_accuracy_14: 0.6090 - dense_1_accuracy_15: 0.6403 - dense_1_accuracy_16: 0.4792 - dense_1_accuracy_17: 0.6528 - dense_1_accuracy_18: 0.6083 - dense_1_accuracy_19: 0.5660 - dense_1_accuracy_2: 0.6521 - dense_1_accuracy_20: 0.6194 - dense_1_accuracy_21: 0.5653 - dense_1_accuracy_22: 0.4681 - dense_1_accuracy_23: 0.4451 - dense_1_accuracy_24: 0.4354 - dense_1_accuracy_25: 0.4146 - dense_1_accuracy_26: 0.4444 - dense_1_accuracy_27: 0.2076 - dense_1_accuracy_28: 0.5847 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6312 - dense_1_accuracy_4: 0.6521 - dense_1_accuracy_5: 0.6736 - dense_1_accuracy_6: 0.6528 - dense_1_accuracy_7: 0.6632 - dense_1_accuracy_8: 0.6743 - dense_1_accuracy_9: 0.6417 - dense_1_loss: 0.0000e+00 - loss: 36.1660\n",
      "Epoch 89/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - dense_1_accuracy: 0.6847 - dense_1_accuracy_1: 0.6618 - dense_1_accuracy_10: 0.6514 - dense_1_accuracy_11: 0.6528 - dense_1_accuracy_12: 0.5757 - dense_1_accuracy_13: 0.5972 - dense_1_accuracy_14: 0.6188 - dense_1_accuracy_15: 0.5986 - dense_1_accuracy_16: 0.4778 - dense_1_accuracy_17: 0.7056 - dense_1_accuracy_18: 0.6299 - dense_1_accuracy_19: 0.5854 - dense_1_accuracy_2: 0.6410 - dense_1_accuracy_20: 0.6403 - dense_1_accuracy_21: 0.5222 - dense_1_accuracy_22: 0.5215 - dense_1_accuracy_23: 0.4674 - dense_1_accuracy_24: 0.4778 - dense_1_accuracy_25: 0.5528 - dense_1_accuracy_26: 0.4125 - dense_1_accuracy_27: 0.2924 - dense_1_accuracy_28: 0.6097 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6514 - dense_1_accuracy_4: 0.6625 - dense_1_accuracy_5: 0.6951 - dense_1_accuracy_6: 0.6944 - dense_1_accuracy_7: 0.6528 - dense_1_accuracy_8: 0.6840 - dense_1_accuracy_9: 0.6306 - dense_1_loss: 0.0000e+00 - loss: 33.6325\n",
      "Epoch 90/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - dense_1_accuracy: 0.6535 - dense_1_accuracy_1: 0.6417 - dense_1_accuracy_10: 0.6097 - dense_1_accuracy_11: 0.6319 - dense_1_accuracy_12: 0.5660 - dense_1_accuracy_13: 0.5437 - dense_1_accuracy_14: 0.5986 - dense_1_accuracy_15: 0.5778 - dense_1_accuracy_16: 0.5014 - dense_1_accuracy_17: 0.6736 - dense_1_accuracy_18: 0.5229 - dense_1_accuracy_19: 0.5757 - dense_1_accuracy_2: 0.6201 - dense_1_accuracy_20: 0.5542 - dense_1_accuracy_21: 0.5674 - dense_1_accuracy_22: 0.4354 - dense_1_accuracy_23: 0.3917 - dense_1_accuracy_24: 0.4896 - dense_1_accuracy_25: 0.3708 - dense_1_accuracy_26: 0.4028 - dense_1_accuracy_27: 0.2722 - dense_1_accuracy_28: 0.5861 - dense_1_accuracy_29: 0.0215 - dense_1_accuracy_3: 0.6208 - dense_1_accuracy_4: 0.6201 - dense_1_accuracy_5: 0.5993 - dense_1_accuracy_6: 0.6632 - dense_1_accuracy_7: 0.6208 - dense_1_accuracy_8: 0.6632 - dense_1_accuracy_9: 0.6208 - dense_1_loss: 0.0000e+00 - loss: 36.6123\n",
      "Epoch 91/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - dense_1_accuracy: 0.7056 - dense_1_accuracy_1: 0.6514 - dense_1_accuracy_10: 0.6299 - dense_1_accuracy_11: 0.6840 - dense_1_accuracy_12: 0.5653 - dense_1_accuracy_13: 0.5757 - dense_1_accuracy_14: 0.6090 - dense_1_accuracy_15: 0.5660 - dense_1_accuracy_16: 0.5111 - dense_1_accuracy_17: 0.6729 - dense_1_accuracy_18: 0.5437 - dense_1_accuracy_19: 0.5653 - dense_1_accuracy_2: 0.6729 - dense_1_accuracy_20: 0.5972 - dense_1_accuracy_21: 0.6076 - dense_1_accuracy_22: 0.5528 - dense_1_accuracy_23: 0.5097 - dense_1_accuracy_24: 0.6292 - dense_1_accuracy_25: 0.4333 - dense_1_accuracy_26: 0.4556 - dense_1_accuracy_27: 0.3160 - dense_1_accuracy_28: 0.6632 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6729 - dense_1_accuracy_4: 0.6403 - dense_1_accuracy_5: 0.6625 - dense_1_accuracy_6: 0.6833 - dense_1_accuracy_7: 0.6729 - dense_1_accuracy_8: 0.6951 - dense_1_accuracy_9: 0.6729 - dense_1_loss: 0.0000e+00 - loss: 34.3842\n",
      "Epoch 92/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - dense_1_accuracy: 0.6743 - dense_1_accuracy_1: 0.6625 - dense_1_accuracy_10: 0.5882 - dense_1_accuracy_11: 0.6729 - dense_1_accuracy_12: 0.6201 - dense_1_accuracy_13: 0.5222 - dense_1_accuracy_14: 0.6410 - dense_1_accuracy_15: 0.5979 - dense_1_accuracy_16: 0.5104 - dense_1_accuracy_17: 0.6097 - dense_1_accuracy_18: 0.5222 - dense_1_accuracy_19: 0.5660 - dense_1_accuracy_2: 0.6194 - dense_1_accuracy_20: 0.6299 - dense_1_accuracy_21: 0.5326 - dense_1_accuracy_22: 0.5333 - dense_1_accuracy_23: 0.4674 - dense_1_accuracy_24: 0.5549 - dense_1_accuracy_25: 0.3688 - dense_1_accuracy_26: 0.4125 - dense_1_accuracy_27: 0.3049 - dense_1_accuracy_28: 0.7181 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6306 - dense_1_accuracy_4: 0.6521 - dense_1_accuracy_5: 0.6514 - dense_1_accuracy_6: 0.6528 - dense_1_accuracy_7: 0.6632 - dense_1_accuracy_8: 0.6097 - dense_1_accuracy_9: 0.6521 - dense_1_loss: 0.0000e+00 - loss: 35.1852\n",
      "Epoch 93/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - dense_1_accuracy: 0.6743 - dense_1_accuracy_1: 0.6521 - dense_1_accuracy_10: 0.6174 - dense_1_accuracy_11: 0.6521 - dense_1_accuracy_12: 0.6292 - dense_1_accuracy_13: 0.5208 - dense_1_accuracy_14: 0.5965 - dense_1_accuracy_15: 0.5750 - dense_1_accuracy_16: 0.5965 - dense_1_accuracy_17: 0.6403 - dense_1_accuracy_18: 0.4986 - dense_1_accuracy_19: 0.5111 - dense_1_accuracy_2: 0.6618 - dense_1_accuracy_20: 0.5111 - dense_1_accuracy_21: 0.4896 - dense_1_accuracy_22: 0.5431 - dense_1_accuracy_23: 0.4243 - dense_1_accuracy_24: 0.5215 - dense_1_accuracy_25: 0.4556 - dense_1_accuracy_26: 0.4451 - dense_1_accuracy_27: 0.1625 - dense_1_accuracy_28: 0.5660 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6507 - dense_1_accuracy_4: 0.6403 - dense_1_accuracy_5: 0.6618 - dense_1_accuracy_6: 0.6944 - dense_1_accuracy_7: 0.6514 - dense_1_accuracy_8: 0.6840 - dense_1_accuracy_9: 0.6514 - dense_1_loss: 0.0000e+00 - loss: 34.9148\n",
      "Epoch 94/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - dense_1_accuracy: 0.6951 - dense_1_accuracy_1: 0.6840 - dense_1_accuracy_10: 0.6618 - dense_1_accuracy_11: 0.6840 - dense_1_accuracy_12: 0.6062 - dense_1_accuracy_13: 0.5854 - dense_1_accuracy_14: 0.6285 - dense_1_accuracy_15: 0.6062 - dense_1_accuracy_16: 0.5951 - dense_1_accuracy_17: 0.6951 - dense_1_accuracy_18: 0.5632 - dense_1_accuracy_19: 0.5646 - dense_1_accuracy_2: 0.6403 - dense_1_accuracy_20: 0.6076 - dense_1_accuracy_21: 0.5208 - dense_1_accuracy_22: 0.5965 - dense_1_accuracy_23: 0.5097 - dense_1_accuracy_24: 0.5194 - dense_1_accuracy_25: 0.4667 - dense_1_accuracy_26: 0.4229 - dense_1_accuracy_27: 0.3028 - dense_1_accuracy_28: 0.6319 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6625 - dense_1_accuracy_4: 0.6729 - dense_1_accuracy_5: 0.6729 - dense_1_accuracy_6: 0.6625 - dense_1_accuracy_7: 0.6944 - dense_1_accuracy_8: 0.7056 - dense_1_accuracy_9: 0.6521 - dense_1_loss: 0.0000e+00 - loss: 33.0418\n",
      "Epoch 95/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - dense_1_accuracy: 0.6535 - dense_1_accuracy_1: 0.6104 - dense_1_accuracy_10: 0.5667 - dense_1_accuracy_11: 0.6528 - dense_1_accuracy_12: 0.4806 - dense_1_accuracy_13: 0.4806 - dense_1_accuracy_14: 0.5347 - dense_1_accuracy_15: 0.5007 - dense_1_accuracy_16: 0.4569 - dense_1_accuracy_17: 0.5986 - dense_1_accuracy_18: 0.5021 - dense_1_accuracy_19: 0.5118 - dense_1_accuracy_2: 0.6208 - dense_1_accuracy_20: 0.5653 - dense_1_accuracy_21: 0.5549 - dense_1_accuracy_22: 0.4042 - dense_1_accuracy_23: 0.4451 - dense_1_accuracy_24: 0.4465 - dense_1_accuracy_25: 0.4681 - dense_1_accuracy_26: 0.4243 - dense_1_accuracy_27: 0.2285 - dense_1_accuracy_28: 0.6507 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6104 - dense_1_accuracy_4: 0.5986 - dense_1_accuracy_5: 0.6208 - dense_1_accuracy_6: 0.5889 - dense_1_accuracy_7: 0.6208 - dense_1_accuracy_8: 0.6535 - dense_1_accuracy_9: 0.6097 - dense_1_loss: 0.0000e+00 - loss: 36.9108\n",
      "Epoch 96/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - dense_1_accuracy: 0.6743 - dense_1_accuracy_1: 0.6194 - dense_1_accuracy_10: 0.6514 - dense_1_accuracy_11: 0.6736 - dense_1_accuracy_12: 0.5549 - dense_1_accuracy_13: 0.5431 - dense_1_accuracy_14: 0.6188 - dense_1_accuracy_15: 0.6194 - dense_1_accuracy_16: 0.4993 - dense_1_accuracy_17: 0.6299 - dense_1_accuracy_18: 0.5646 - dense_1_accuracy_19: 0.5542 - dense_1_accuracy_2: 0.6299 - dense_1_accuracy_20: 0.5979 - dense_1_accuracy_21: 0.6299 - dense_1_accuracy_22: 0.5431 - dense_1_accuracy_23: 0.4681 - dense_1_accuracy_24: 0.4993 - dense_1_accuracy_25: 0.4354 - dense_1_accuracy_26: 0.4458 - dense_1_accuracy_27: 0.3056 - dense_1_accuracy_28: 0.5771 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6417 - dense_1_accuracy_4: 0.6188 - dense_1_accuracy_5: 0.6410 - dense_1_accuracy_6: 0.6729 - dense_1_accuracy_7: 0.6736 - dense_1_accuracy_8: 0.6847 - dense_1_accuracy_9: 0.6625 - dense_1_loss: 0.0000e+00 - loss: 34.3398\n",
      "Epoch 97/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - dense_1_accuracy: 0.6951 - dense_1_accuracy_1: 0.6625 - dense_1_accuracy_10: 0.6625 - dense_1_accuracy_11: 0.6417 - dense_1_accuracy_12: 0.6076 - dense_1_accuracy_13: 0.5757 - dense_1_accuracy_14: 0.5979 - dense_1_accuracy_15: 0.5868 - dense_1_accuracy_16: 0.5312 - dense_1_accuracy_17: 0.5764 - dense_1_accuracy_18: 0.5222 - dense_1_accuracy_19: 0.5972 - dense_1_accuracy_2: 0.6625 - dense_1_accuracy_20: 0.6083 - dense_1_accuracy_21: 0.5437 - dense_1_accuracy_22: 0.4569 - dense_1_accuracy_23: 0.5007 - dense_1_accuracy_24: 0.5868 - dense_1_accuracy_25: 0.5215 - dense_1_accuracy_26: 0.4347 - dense_1_accuracy_27: 0.2715 - dense_1_accuracy_28: 0.6424 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6299 - dense_1_accuracy_4: 0.6729 - dense_1_accuracy_5: 0.6090 - dense_1_accuracy_6: 0.6417 - dense_1_accuracy_7: 0.6736 - dense_1_accuracy_8: 0.6625 - dense_1_accuracy_9: 0.6521 - dense_1_loss: 0.0000e+00 - loss: 34.3261\n",
      "Epoch 98/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - dense_1_accuracy: 0.6743 - dense_1_accuracy_1: 0.6097 - dense_1_accuracy_10: 0.6090 - dense_1_accuracy_11: 0.6736 - dense_1_accuracy_12: 0.5986 - dense_1_accuracy_13: 0.5319 - dense_1_accuracy_14: 0.5868 - dense_1_accuracy_15: 0.6201 - dense_1_accuracy_16: 0.4785 - dense_1_accuracy_17: 0.6097 - dense_1_accuracy_18: 0.5437 - dense_1_accuracy_19: 0.5326 - dense_1_accuracy_2: 0.6306 - dense_1_accuracy_20: 0.5653 - dense_1_accuracy_21: 0.5861 - dense_1_accuracy_22: 0.5215 - dense_1_accuracy_23: 0.3799 - dense_1_accuracy_24: 0.5000 - dense_1_accuracy_25: 0.4458 - dense_1_accuracy_26: 0.3812 - dense_1_accuracy_27: 0.3160 - dense_1_accuracy_28: 0.7056 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6312 - dense_1_accuracy_4: 0.6097 - dense_1_accuracy_5: 0.6306 - dense_1_accuracy_6: 0.6528 - dense_1_accuracy_7: 0.6521 - dense_1_accuracy_8: 0.6312 - dense_1_accuracy_9: 0.6417 - dense_1_loss: 0.0000e+00 - loss: 35.7293\n",
      "Epoch 99/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - dense_1_accuracy: 0.7056 - dense_1_accuracy_1: 0.6833 - dense_1_accuracy_10: 0.6410 - dense_1_accuracy_11: 0.6944 - dense_1_accuracy_12: 0.5542 - dense_1_accuracy_13: 0.5007 - dense_1_accuracy_14: 0.6299 - dense_1_accuracy_15: 0.6417 - dense_1_accuracy_16: 0.5104 - dense_1_accuracy_17: 0.6521 - dense_1_accuracy_18: 0.5868 - dense_1_accuracy_19: 0.5861 - dense_1_accuracy_2: 0.6729 - dense_1_accuracy_20: 0.5750 - dense_1_accuracy_21: 0.5646 - dense_1_accuracy_22: 0.5208 - dense_1_accuracy_23: 0.4562 - dense_1_accuracy_24: 0.5326 - dense_1_accuracy_25: 0.4986 - dense_1_accuracy_26: 0.4778 - dense_1_accuracy_27: 0.2826 - dense_1_accuracy_28: 0.7715 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6403 - dense_1_accuracy_4: 0.6299 - dense_1_accuracy_5: 0.6514 - dense_1_accuracy_6: 0.6729 - dense_1_accuracy_7: 0.6736 - dense_1_accuracy_8: 0.6840 - dense_1_accuracy_9: 0.6944 - dense_1_loss: 0.0000e+00 - loss: 34.1379\n",
      "Epoch 100/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - dense_1_accuracy: 0.6743 - dense_1_accuracy_1: 0.6417 - dense_1_accuracy_10: 0.6090 - dense_1_accuracy_11: 0.6625 - dense_1_accuracy_12: 0.5118 - dense_1_accuracy_13: 0.6083 - dense_1_accuracy_14: 0.5875 - dense_1_accuracy_15: 0.6201 - dense_1_accuracy_16: 0.4667 - dense_1_accuracy_17: 0.6424 - dense_1_accuracy_18: 0.5542 - dense_1_accuracy_19: 0.5757 - dense_1_accuracy_2: 0.6521 - dense_1_accuracy_20: 0.5764 - dense_1_accuracy_21: 0.5972 - dense_1_accuracy_22: 0.5007 - dense_1_accuracy_23: 0.5319 - dense_1_accuracy_24: 0.5208 - dense_1_accuracy_25: 0.4257 - dense_1_accuracy_26: 0.4569 - dense_1_accuracy_27: 0.2938 - dense_1_accuracy_28: 0.6514 - dense_1_accuracy_29: 0.0000e+00 - dense_1_accuracy_3: 0.6417 - dense_1_accuracy_4: 0.6201 - dense_1_accuracy_5: 0.6201 - dense_1_accuracy_6: 0.6201 - dense_1_accuracy_7: 0.6528 - dense_1_accuracy_8: 0.6743 - dense_1_accuracy_9: 0.6417 - dense_1_loss: 0.0000e+00 - loss: 35.5993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7cd9c7c7a330>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X, a0, c0], list(Y), epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should see the model loss going down. Now that we have trained a model, lets go on the the final section to implement an inference algorithm, and generate some music! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id=\"6\"></a>\n",
    "<h1 style=\"background: #FFC07F; border: 0; color: #2F2E41; \n",
    "    box-shadow: 4px 4px 8px rgba(0, 0, 0, 0.3); \n",
    "    padding: 10px; border-radius: 10px; margin: 15px 0;\">\n",
    "    <center style=\"color: #2F2E41;\">6 - Model Inference - Generating music</center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Having trained the model to recognize and learn the patterns of the jazz soloist, we can now leverage this model to synthesize new musical compositions.\n",
    "\n",
    "<a id=\"6-1\"></a>\n",
    "\n",
    "### 6.1 - Predicting & Sampling\n",
    "\n",
    "<img src=\"images/music_gen.png\" style=\"width:600;height:400px;\">\n",
    "\n",
    "During each step of the sampling process, the model will use the activation vector $a$ and cell state $c$ from the previous time step of the LSTM. It will then perform one step of forward propagation, generating a new output activation and corresponding cell state. The updated activation $a$ will be passed through the `densor` layer to generate the output for the current time step.\n",
    "\n",
    "The next function `music_inference_model` we will build facilitates this inference. It will accept the trained model and the desired number of time steps, $T_y$, to generate. The function will return a Keras model capable of synthesizing sequences of musical values. Additionally, the function will incorporate a dense layer with $90$ units and the specified number of activations.\n",
    "\n",
    "**Step 1:** To initiate the generation process, we will start by setting the input $x_0$ and both the LSTM activation and cell states, $a_0$ and $c_0$, to zero vectors.\n",
    "\n",
    " **Step 2:** The following key steps should be implemented within the for-loop to produce the $T_y$ output values:\n",
    "\n",
    "- **Step 2.A:** Use `LSTM_Cell` to process the previous time step's activation $a$ and cell state $c$ in order to compute the current step's updated activation and cell state.\n",
    "  \n",
    "- **Step 2.B:** Pass the updated activation $a$ through the `densor` layer, applying a softmax function to obtain the output for the current time step.\n",
    "  \n",
    "- **Step 2.C:** Append the output generated in Step 2.B to the list of outputs.\n",
    "  \n",
    "- **Step 2.D:** Convert the output $a$ to a one-hot vector using the following line of code, which performs the sampling:\n",
    "  ```python\n",
    "  x = Lambda(one_hot)(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def music_inference_model(LSTM_cell, densor, n_values = 90, n_a = 64, Ty = 100):\n",
    "    \"\"\"\n",
    "    Uses the trained \"LSTM_cell\" and \"densor\" from model() to generate a sequence of values.\n",
    "    \n",
    "    Arguments:\n",
    "    LSTM_cell -- the trained \"LSTM_cell\" from model(), Keras layer object\n",
    "    densor -- the trained \"densor\" from model(), Keras layer object\n",
    "    n_values -- integer, umber of unique values\n",
    "    n_a -- number of units in the LSTM_cell\n",
    "    Ty -- integer, number of time steps to generate\n",
    "    \n",
    "    Returns:\n",
    "    inference_model -- Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input of your model with a shape \n",
    "    x0 = Input(shape=(1, n_values))\n",
    "    \n",
    "    # Define s0, initial hidden state for the decoder LSTM\n",
    "    a0 = Input(shape=(n_a,), name='a0')\n",
    "    c0 = Input(shape=(n_a,), name='c0')\n",
    "    a = a0\n",
    "    c = c0\n",
    "    x = x0\n",
    "\n",
    "\n",
    "    # Step 1: Create an empty list of \"outputs\" to later store your predicted values (≈1 line)\n",
    "    outputs = []\n",
    "    \n",
    "    # Step 2: Loop over Ty and generate a value at every time step\n",
    "    for t in range(Ty):\n",
    "        \n",
    "        # Step 2.A: Perform one step of LSTM_cell (≈1 line)\n",
    "        a, _, c = LSTM_cell(x, initial_state=[a, c])\n",
    "        \n",
    "        # Step 2.B: Apply Dense layer to the hidden state output of the LSTM_cell (≈1 line)\n",
    "        out = densor(a)\n",
    "\n",
    "        # Step 2.C: Append the prediction \"out\" to \"outputs\". out.shape = (None, 78) (≈1 line)\n",
    "        outputs.append(out)\n",
    "        \n",
    "        # Step 2.D: Select the next value according to \"out\", and set \"x\" to be the one-hot representation of the\n",
    "        #           selected value, which will be passed as the input to LSTM_cell on the next step. We have provided \n",
    "        #           the line of code you need to do this. \n",
    "        x = Lambda(one_hot, output_shape=(1, n_values))(out)  # Shape will be (batch_size, 1, n_values)\n",
    "\n",
    "        \n",
    "    # Step 3: Create model instance with the correct \"inputs\" and \"outputs\" (≈1 line)\n",
    "    inference_model = Model(inputs=[x0, a0, c0], outputs=outputs)\n",
    "    \n",
    "    \n",
    "    return inference_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define our inference model. This model is hard coded to generate 50 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_model = music_inference_model(LSTM_cell, densor, n_values = 90, n_a = 64, Ty = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, this step initializes the zero-valued vectors that will be used to set the initial values for the input $x$ and the LSTM state variables, $a$ and $c$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_initializer = np.zeros((1, 1, 90))\n",
    "a_initializer = np.zeros((1, n_a))\n",
    "c_initializer = np.zeros((1, n_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will implement `predict_and_sample()`. This function takes many arguments including the inputs [x_initializer, a_initializer, c_initializer]. In order to predict the output corresponding to this input, we will need to carry-out 3 steps:\n",
    "1. Use our inference model to predict an output given your set of inputs. The output `pred` should be a list of length $T_y$ where each element is a numpy-array of shape (1, n_values).\n",
    "2. Convert `pred` into a numpy array of $T_y$ indices. Each index corresponds is computed by taking the `argmax` of an element of the `pred` list. [Hint](https://docs.scipy.org/doc/numpy/reference/generated/numpy.argmax.html).\n",
    "3. Convert the indices into their one-hot vector representations. [Hint](https://keras.io/utils/#to_categorical)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_and_sample(inference_model, x_initializer = x_initializer, a_initializer = a_initializer, \n",
    "                       c_initializer = c_initializer):\n",
    "    \"\"\"\n",
    "    Predicts the next value of values using the inference model.\n",
    "    \n",
    "    Arguments:\n",
    "    inference_model -- Keras model instance for inference time\n",
    "    x_initializer -- numpy array of shape (1, 1, 78), one-hot vector initializing the values generation\n",
    "    a_initializer -- numpy array of shape (1, n_a), initializing the hidden state of the LSTM_cell\n",
    "    c_initializer -- numpy array of shape (1, n_a), initializing the cell state of the LSTM_cel\n",
    "    \n",
    "    Returns:\n",
    "    results -- numpy-array of shape (Ty, 78), matrix of one-hot vectors representing the values generated\n",
    "    indices -- numpy-array of shape (Ty, 1), matrix of indices representing the values generated\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Use our  inference model to predict an output sequence given x_initializer, a_initializer and c_initializer.\n",
    "    pred = inference_model.predict([x_initializer, a_initializer, c_initializer])\n",
    "    # Step 2: Convert \"pred\" into an np.array() of indices with the maximum probabilities\n",
    "    indices = np.argmax(pred, axis=-1)\n",
    "    # Step 3: Convert indices to one-hot vectors, the shape of the results should be (1, )\n",
    "    results = to_categorical(indices, num_classes=90)\n",
    "\n",
    "    \n",
    "    return results, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.argmax(results[12]) = 35\n",
      "np.argmax(results[17]) = 15\n",
      "list(indices[12:18]) = [array([35]), array([1]), array([41]), array([41]), array([15]), array([15])]\n"
     ]
    }
   ],
   "source": [
    "results, indices = predict_and_sample(inference_model, x_initializer, a_initializer, c_initializer)\n",
    "print(\"np.argmax(results[12]) =\", np.argmax(results[12]))\n",
    "print(\"np.argmax(results[17]) =\", np.argmax(results[17]))\n",
    "print(\"list(indices[12:18]) =\", list(indices[12:18]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6-2\"></a>\n",
    "\n",
    "#### 6.2 - Generating Music\n",
    "\n",
    "With the model trained, we can now proceed to generate music. The RNN generates a sequence of values, which can then be post-processed into musical chords, allowing multiple notes or values to be played simultaneously. \n",
    "\n",
    "It is important to note that most computational music generation algorithms, including this one, utilize post-processing techniques. These techniques are crucial because generating music that is both coherent and pleasing to the ear involves more than just the raw output of the RNN. Post-processing typically addresses several aspects of the generated music, such as:\n",
    "\n",
    "- Ensuring that the same sound is not repeated excessively,\n",
    "- Avoiding large pitch intervals between successive notes,\n",
    "- Creating smooth transitions between notes, and so on.\n",
    "\n",
    "While some might argue that these post-processing steps are somewhat heuristic, they have proven to be essential in producing high-quality output. In fact, much of the work in the music generation literature has focused on handcrafting such post-processors. The quality of the generated music often hinges on the effectiveness of the post-processing phase, sometimes even more so than the RNN itself.\n",
    "\n",
    "For this implementation, we will incorporate these post-processing steps to enhance the output. Now, let us proceed to generate some music!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run the following cell to generate a sequence of music using the trained model and record the output into the `out_stream` object. Please note that this process may take a couple of minutes, as the model synthesizes the music and processes it into a final sequence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting new values for different set of chords.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Generated 19 sounds using the predicted values for the set of chords (\"1\") and after pruning\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Generated 19 sounds using the predicted values for the set of chords (\"2\") and after pruning\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Generated 19 sounds using the predicted values for the set of chords (\"3\") and after pruning\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Generated 19 sounds using the predicted values for the set of chords (\"4\") and after pruning\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Generated 19 sounds using the predicted values for the set of chords (\"5\") and after pruning\n",
      "Your generated music is saved in output/my_music.midi\n"
     ]
    }
   ],
   "source": [
    "out_stream = generate_music(inference_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert the generated midi file to mp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter '/home/codespace/.fluidsynth/default_sound_font.sf2' not a SoundFont or MIDI file or error occurred identifying it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.1.1\n",
      "Copyright (C) 2000-2020 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
      "\n",
      "Rendering audio to file 'output/my_music.wav'..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Guessed Channel Layout for Input Stream #0.0 : stereo\n",
      "Input #0, wav, from 'output/my_music.wav':\n",
      "  Duration: 00:00:15.00, bitrate: 1411 kb/s\n",
      "    Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (pcm_s16le (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp3, to 'output/my_music.mp3':\n",
      "  Metadata:\n",
      "    TSSE            : Lavf58.29.100\n",
      "    Stream #0:0: Audio: mp3 (libmp3lame), 44100 Hz, stereo, s16p\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 libmp3lame\n",
      "size=     235kB time=00:00:15.02 bitrate= 128.3kbits/s speed=89.9x    \n",
      "video:0kB audio:235kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.105091%\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "def convert_midi_to_mp3(midi_file, wav_file, mp3_file):\n",
    "    \"\"\"Converts a MIDI file to MP3.\n",
    "\n",
    "    Args:\n",
    "        midi_file (str): Path to the input MIDI file.\n",
    "        mp3_file (str): Path to the output MP3 file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert MIDI to WAV using midi2audio\n",
    "    subprocess.call([\"midi2audio\",  midi_file, wav_file])\n",
    "\n",
    "    # Convert WAV to MP3 using FFmpeg\n",
    "    subprocess.call([\"ffmpeg\", \"-i\", wav_file, mp3_file])\n",
    "\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "midi_file = \"output/my_music.midi\"\n",
    "mp3_file = \"output/my_music.mp3\"\n",
    "wav_file = \"output/my_music.wav\"\n",
    "convert_midi_to_mp3(midi_file, wav_file, mp3_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Listen to the generated music here <br><br>\n",
    "<audio controls>\n",
    "    <source src=\"https://raw.githubusercontent.com/umermjd11/DLC5M1A3/master/output/my_music.mp3\" type=\"audio/mp3\">\n",
    "    Your browser does not support the audio element.\n",
    "</audio>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a>\n",
    "<h1 style=\"background: #FFC07F; border: 0; color: #2F2E41; \n",
    "    box-shadow: 4px 4px 8px rgba(0, 0, 0, 0.3); \n",
    "    padding: 10px; border-radius: 10px; margin: 15px 0;\">\n",
    "    <center style=\"color: #2F2E41;\">7 - Congratulations!</center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We have successfully completed this notebook.\n",
    "\n",
    "<font color=\"blue\">\n",
    "Key takeaways:\n",
    "- Sequence models are effective tools for generating musical values, which can subsequently be transformed into MIDI music through post-processing.\n",
    "- While the model structure remains similar for tasks such as generating dinosaur names or music, the key distinction lies in the input data fed into the model.\n",
    "- In Keras, sequence generation involves defining layers with shared weights, which are applied across multiple time steps ($1, \\ldots, T_x$), ensuring consistency in model behavior throughout the sequence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"8\"></a>\n",
    "<h1 style=\"background: #FFC07F; border: 0; color: #2F2E41; \n",
    "    box-shadow: 4px 4px 8px rgba(0, 0, 0, 0.3); \n",
    "    padding: 10px; border-radius: 10px; margin: 15px 0;\">\n",
    "    <center style=\"color: #2F2E41;\">8 - References!</center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The ideas presented in this notebook came primarily from three computational music papers cited below. The implementation here also took significant inspiration and used many components from Ji-Sung Kim's github repository.\n",
    "\n",
    "- Ji-Sung Kim, 2016, [deepjazz](https://github.com/jisungk/deepjazz)\n",
    "- Jon Gillick, Kevin Tang and Robert Keller, 2009. [Learning Jazz Grammars](http://ai.stanford.edu/~kdtang/papers/smc09-jazzgrammar.pdf)\n",
    "- Robert Keller and David Morrison, 2007, [A Grammatical Approach to Automatic Improvisation](http://smc07.uoa.gr/SMC07%20Proceedings/SMC07%20Paper%2055.pdf)\n",
    "- François Pachet, 1999, [Surprising Harmonies](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.5.7473&rep=rep1&type=pdf)\n",
    "\n",
    "We're also grateful to François Germain for valuable feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "nlp-sequence-models",
   "graded_item_id": "EG0F7",
   "launcher_item_id": "cxJXc"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
